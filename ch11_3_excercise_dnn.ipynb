{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "- Tune the hyperparameters using cross-validation and see what precision you can achieve. \n",
    "- Now try adding Batch Normalization and compare the learning curves: is it converging faster than before? Does it produce a better model? \n",
    "- Is the model overfitting the training set? Try adding dropout to every layer and try again. Does it help?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frame\n",
    "- Create predictor class \"DNN_Classifier\" using DNN with hyper parameters\n",
    "    - implement __init__, fit, predict and predict_prob\n",
    "    - Fit will use class DNN_Helper with methods create_graph(which will create tensor flow graph) and train_dnn (which will train dnn with given hyper-parameters)\n",
    "    - create_graph will use hyper-parameters like number of neurons, activation function, optimizer class, learning rate etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Notes About Graph and Session\n",
    "- Tensorflow computations are represented as graph which indicates operands, operations and their dependencies.\n",
    "- Graph is run within context of Session which stores current state of the computations\n",
    "- When creating a tensor or an operation it is automatically added to default graph\n",
    "- We can also create another graph and make it default using \n",
    "       \n",
    "       ``` python\n",
    "           with graph.as_default():\n",
    "               # add tensors and operations\n",
    "       ```\n",
    "       \n",
    "- No computation are run until it is run inside the context of a session\n",
    "    \n",
    "    ``` python\n",
    "        # The session will use current default graph\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(op)\n",
    "        \n",
    "        # The session will use graph sent as parameter\n",
    "        with tf.Session(graph=graph) as sess:\n",
    "            sess.run(op)\n",
    "        \n",
    "    ```\n",
    "    \n",
    "- ```tf.train.Saver``` can be used to save session and restore it latter when needed\n",
    "    \n",
    "    ``` python\n",
    "    saver.save(session, path)\n",
    "    saver.restore(session,path)\n",
    "    ```\n",
    "    \n",
    "- Graph must be created before restoring the session. To restore graph also from the checkpoint file use following code which will restore graph as default graph\n",
    "``` python\n",
    "    meta_importer = tf.train.import_meta_graph(checkpoint_path+\".meta\")\n",
    "    \n",
    "    # Then restore session\n",
    "    sess = tf.Session()\n",
    "    meta_importer.restore(sess, checkpoint_path)\n",
    "```\n",
    "\n",
    "- When restoring graph from meta file our tensor and operation variables are not assigned automatically. So we need to find them in graph by name or other way and assign it to variables to easily use them. Some functions are\n",
    "  - ```graph.get_tensor_by_name(\"x:0\")``` here 0 indicates 1st output of operation x\n",
    "  - ```graph.get_operation_by_name(\"is_training\")```\n",
    "  - ```graph.collections``` is list of collection names\n",
    "  - ```tf.get_collection(collection_name)``` will give all variables in a collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MINST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train.astype(np.float32).reshape(-1, 28*28)/255.0\n",
    "x_test = x_test.astype(np.float32).reshape(-1, 28*28)/255.0\n",
    "\n",
    "train_indxes_0to4 = y_train<5\n",
    "train_x_0to4 = x_train[train_indxes_0to4]\n",
    "train_y_0to4 = y_train[train_indxes_0to4]\n",
    "\n",
    "test_indxes_0to4 = y_test<5\n",
    "test_x_0to4 = x_test[test_indxes_0to4]\n",
    "test_y_0to4 = y_test[test_indxes_0to4]\n",
    "\n",
    "\n",
    "\n",
    "(train_x_0to4, val_x_0to4, train_y_0to4, val_y_0to4) = \\\n",
    "    train_test_split(train_x_0to4, train_y_0to4, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/devbhadurkhadka/.pyenv/versions/anaconda3-5.2.0/envs/scikit_practice/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import variance_scaling_initializer as he_initializer\n",
    "from tensorflow.nn import sparse_softmax_cross_entropy_with_logits as softmax_xentropy\n",
    "from tensorflow.layers import dense\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_leaky_relu(alpha):\n",
    "    return lambda z, name=None: tf.maximum(alpha*z,z, name=name)\n",
    "    \n",
    "\n",
    "def get_connected_layers(x, n_hidden_layers, n_neurons, n_ouputs, activation=tf.nn.elu,\n",
    "                                   batch_norm_momentum=None, dropout_rate=None, is_training=None):\n",
    "    \n",
    "\n",
    "    initializer = he_initializer()\n",
    "    \n",
    "    with tf.name_scope(\"DNN\"):\n",
    "        inputs = x\n",
    "        for l in range(n_hidden_layers):\n",
    "            if dropout_rate is not None:\n",
    "                ## this function will set inputs to zero with dropout rate probability\n",
    "                ## and divides remaining inputs with dropout rate\n",
    "                inputs = tf.layers.dropout(inputs, dropout_rate, training=is_training, \n",
    "                                  name=(\"dropout%d\"%l))\n",
    "                \n",
    "            inputs = tf.layers.dense(inputs, n_neurons, kernel_initializer=initializer,\n",
    "                           name=\"hidden%d\"%(l+1), activation=activation)\n",
    "            \n",
    "            if batch_norm_momentum is not None:\n",
    "                inputs = tf.layers.batch_normalization(inputs, momentum=batch_norm_momentum,\n",
    "                                training=is_training)\n",
    "            \n",
    "            inputs = activation(inputs, name=\"hiden%d_out\"%(l+1))\n",
    "            \n",
    "        output = tf.layers.dense(inputs, n_ouputs, name=\"output\")\n",
    "        \n",
    "    return output\n",
    "        \n",
    "\n",
    "\n",
    "def get_softmax_xentropy_loss(logits,y):\n",
    "    with tf.name_scope(\"loss\"):\n",
    "        xentropy = softmax_xentropy(labels=y, logits=logits)\n",
    "        return tf.reduce_mean(xentropy, name=\"mean_loss\")\n",
    "\n",
    "def get_optimizer_op(optimizer, loss, learning_rate=0.01):\n",
    "    with tf.name_scope(\"train\"):\n",
    "        optimizer =  optimizer(learning_rate=learning_rate)\n",
    "        optimizer_op = optimizer.minimize(loss, name=\"optimizer_op\")\n",
    "    return optimizer_op\n",
    "\n",
    "def get_validation_score(logits,y):\n",
    "    with tf.name_scope(\"validation\"):\n",
    "        preds = tf.nn.in_top_k(logits,y,1)\n",
    "        return tf.reduce_mean(tf.cast(preds, dtype=np.float32), name=\"validation_score\")\n",
    "    \n",
    "def get_batch(x,y,batch_size):\n",
    "    n_batches = len(y)//batch_size + 1\n",
    "    for i in range(n_batches):\n",
    "        indxes = np.random.choice(len(y), size=batch_size, replace=False)\n",
    "        yield x[indxes], y[indxes]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Classifier Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imp import reload\n",
    "# import my_libs\n",
    "# reload(my_libs.tf_graph_saver)\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from my_libs.tf_graph_saver import ScalerGraphSaver2\n",
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "\n",
    "\n",
    "class DNN_Classifier(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_hidden_layers=None, n_neurons=None, n_outputs=None, \n",
    "                 activation=tf.nn.elu, optimizer=tf.train.AdamOptimizer,  learning_rate=0.01, \n",
    "                 batch_norm_momentum=None, batch_size=50, dropout_rate=None):\n",
    "        self.n_hidden_layers = n_hidden_layers\n",
    "        self.n_neurons = n_neurons\n",
    "        self.learning_rate = learning_rate\n",
    "        self.activation = activation\n",
    "        self.optimizer = optimizer\n",
    "        self.batch_norm_momentum = batch_norm_momentum\n",
    "        self.batch_size = batch_size\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.n_outputs = n_outputs\n",
    "        self._session = None\n",
    "        \n",
    "        \n",
    "    def _create_graph(self):                      \n",
    "        \n",
    "        tf.reset_default_graph()\n",
    "        self._graph = tf.Graph()\n",
    "        with self._graph.as_default():\n",
    "        \n",
    "            self._x = tf.placeholder(shape=(None, 28*28), dtype=np.float32,name=\"x\")\n",
    "            self._y = tf.placeholder(shape=(None), dtype=np.int32,name=\"y\")\n",
    "\n",
    "            self._is_training = tf.placeholder_with_default(False,shape=(), name=\"is_training\")\n",
    "\n",
    "\n",
    "            self._dnn = get_connected_layers(self._x, self.n_hidden_layers, self.n_neurons, \n",
    "                                       self.n_outputs, activation=self.activation, \n",
    "                                       batch_norm_momentum=self.batch_norm_momentum, \n",
    "                                       dropout_rate=self.dropout_rate, is_training=self._is_training)\n",
    "            self._loss = get_softmax_xentropy_loss(self._dnn, self._y)\n",
    "            self._optimizer_op = get_optimizer_op(self.optimizer, self._loss, \n",
    "                                                  self.learning_rate)\n",
    "            self._validation_score = get_validation_score(self._dnn, self._y)\n",
    "\n",
    "            self._y_proba = tf.nn.softmax(self._dnn, name=\"y_proba\")\n",
    "\n",
    "            self._batch_norm_update_ops = self._graph.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "            self._saver = tf.train.Saver()\n",
    "            self._init = tf.global_variables_initializer()\n",
    "            \n",
    "        \n",
    "    def _save_params(self):\n",
    "        with self._graph.as_default():\n",
    "            global_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "            \n",
    "        vars_n_values = {global_var.op.name:value for global_var, value in \\\n",
    "                 zip(global_vars,self._session.run(global_vars))}\n",
    "        self._saved_params =  vars_n_values\n",
    "        \n",
    "    \n",
    "    def _restore_params(self):\n",
    "        var_names = list(self._saved_params.keys())\n",
    "        \n",
    "        ## get assign operations for all variables\n",
    "        assign_ops = {var_name:self._graph.get_operation_by_name(\"%s/Assign\"%var_name) \n",
    "                      for var_name in var_names}\n",
    "        ## get initialization values of all variables\n",
    "        init_values = {var_name: assign_op.inputs[1]  for var_name, assign_op \n",
    "                       in assign_ops.items()}\n",
    "        \n",
    "        ## get feed_dict for all values\n",
    "        feed_dict = {init_values[var_name]:self._saved_params[var_name] \n",
    "                     for var_name in var_names}\n",
    "        \n",
    "        \n",
    "        self._session.run(assign_ops, feed_dict=feed_dict)\n",
    "        \n",
    "    \n",
    "    def fit(self,x,y,x_val,y_val):\n",
    "        n_epoches = 500\n",
    "        max_epoches_wo_progress = 30\n",
    "        \n",
    "        self._create_graph()\n",
    "        \n",
    "        best_score=np.float(\"inf\")\n",
    "        best_epoch=0\n",
    "        if self._session: self._session.close()\n",
    "        with tf.Session(graph=self._graph).as_default() as sess:\n",
    "            self._session = sess\n",
    "            sess.run(self._init)\n",
    "            \n",
    "            graph_saver = ScalerGraphSaver2(\"DNN_GridSearch\")\n",
    "            loss_summary = graph_saver.get_summary_op(\"loss\", self._loss)\n",
    "            score_summary = graph_saver.get_summary_op(\"accuracy_score\", self._validation_score)\n",
    "            \n",
    "            with graph_saver:\n",
    "        \n",
    "                for epoch in range(n_epoches):\n",
    "                    for batch_x, batch_y in get_batch(x,y,self.batch_size):\n",
    "                        ops = [self._loss, loss_summary, self._optimizer_op]\n",
    "                        if self._batch_norm_update_ops is not None:\n",
    "                            ops.append(self._batch_norm_update_ops)\n",
    "\n",
    "                        results = sess.run(ops , feed_dict={self._x:batch_x, self._y:batch_y, \n",
    "                                               self._is_training:True})\n",
    "                        loss = results[0]\n",
    "                        loss_summary_text = results[1]\n",
    "\n",
    "\n",
    "\n",
    "                    score, score_summary_text = sess.run([self._validation_score, score_summary], \n",
    "                                     feed_dict={self._x:x_val, self._y:y_val})\n",
    "                    graph_saver.log_summary(loss_summary_text, epoch)\n",
    "                    graph_saver.log_summary(score_summary_text, epoch)\n",
    "                    \n",
    "                   \n",
    "                    \n",
    "                    if epoch%20 == 0:\n",
    "                        print(\"epoch %d, score %f, loss %f\"%(epoch, score, loss))\n",
    "                    \n",
    "                    score=loss\n",
    "                    if score < best_score:\n",
    "                        best_score = score\n",
    "                        best_epoch = epoch\n",
    "                        self._save_params()\n",
    "                    elif (epoch - best_epoch)>max_epoches_wo_progress:\n",
    "                        print(\"No progress for %d epoches.\"%max_epoches_wo_progress)\n",
    "                        break\n",
    "                \n",
    "            self._restore_params()\n",
    "            print(\"Reverting back to epoch %d \\\n",
    "                    with %f score\" %(best_epoch, best_score))\n",
    "            self._score = best_score \n",
    "            return self\n",
    "            \n",
    "                    \n",
    "    \n",
    "    def predict_proba(self,x):\n",
    "        if self._session is None:\n",
    "            raise NotFittedError(\"%s is not fitted yet\" \\\n",
    "                                                    %self.__class__.__name__)\n",
    "        \n",
    "        return self._session.run(self._y_proba, feed_dict={self._x:x, \n",
    "                                                           self._is_training:False})\n",
    "            \n",
    "    \n",
    "    def predict(self,x):\n",
    "        return np.argmax(self.predict_proba(x), axis=1)\n",
    "    \n",
    "    def score(self, x_val=None, y_val=None):\n",
    "        \n",
    "        score=self._session.run(self._validation_score, \n",
    "                             feed_dict={self._x:x_val, self._y:y_val})\n",
    "        print(\"validation score: %f\", score)\n",
    "        return score\n",
    "    \n",
    "    def _get_save_path(self, name):\n",
    "        return \"tf_checkpoints/%s\"%name\n",
    "    \n",
    "    def save(self,name):\n",
    "        self._saver.save(self._session, self._get_save_path(name))\n",
    "    \n",
    "    def restore(self, name):\n",
    "        imported_meta = tf.train.import_meta_graph(\"%s.meta\"%self._get_save_path(name))\n",
    "        graph = tf.get_default_graph()\n",
    "        self._x = graph.get_tensor_by_name(\"x:0\")\n",
    "        self._y = graph.get_tensor_by_name(\"y:0\")\n",
    "        self._loss = graph.get_operation_by_name(\"mean_loss\")\n",
    "        \n",
    "        self._validation_score = graph.get_tensor_by_name(\"validation/validation_score:0\")\n",
    "        self._y_proba = graph.get_tensor_by_name(\"y_proba:0\")\n",
    "        self._is_training = graph.get_tensor_by_name(\"is_training:0\")\n",
    "        self._session = tf.Session(graph=graph)\n",
    "        imported_meta.restore(self._session, self._get_save_path(name))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0905 20:32:21.044908 4513576384 deprecation.py:323] From <ipython-input-4-99b76afb2362>:28: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "W0905 20:32:21.751328 4513576384 deprecation.py:506] From /Users/devbhadurkhadka/.pyenv/versions/anaconda3-5.2.0/envs/scikit_practice/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0905 20:32:21.811959 4513576384 deprecation.py:323] From /Users/devbhadurkhadka/.pyenv/versions/anaconda3-5.2.0/envs/scikit_practice/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0905 20:32:22.113808 4513576384 deprecation_wrapper.py:119] From /Volumes/Projects/Machine Learning/tensorflow_practice/my_libs/tf_graph_saver.py:46: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, score 0.967647, loss 0.211136\n",
      "epoch 20, score 0.983987, loss 0.000414\n",
      "epoch 40, score 0.979085, loss 0.018174\n",
      "epoch 60, score 0.983987, loss 0.000002\n",
      "epoch 80, score 0.984314, loss 0.006435\n",
      "epoch 100, score 0.982026, loss 0.000044\n",
      "No progress for 30 epoches.\n",
      "Reverting back to epoch 72                     with 0.000000 score\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNN_Classifier(activation=<function get_leaky_relu.<locals>.<lambda> at 0x1a38098510>,\n",
       "        batch_norm_momentum=None, batch_size=50, dropout_rate=None,\n",
       "        learning_rate=0.01, n_hidden_layers=2, n_neurons=20, n_outputs=5,\n",
       "        optimizer=<class 'tensorflow.python.training.adam.AdamOptimizer'>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = DNN_Classifier(2, 20, 5, activation=get_leaky_relu(0.01))\n",
    "classifier.fit(train_x_0to4, train_y_0to4, val_x_0to4, val_y_0to4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save(\"Mnist-0to4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"The name 'mean_loss' refers to an Operation not in the graph.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-6e17bdf8e7fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclas_re\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDNN_Classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclas_re\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mnist-0to4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclas_re\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x_0to4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y_0to4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-69e163429700>\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_operation_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mean_loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validation_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"validation/validation_score:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.2.0/envs/scikit_practice/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_operation_by_name\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   3922\u001b[0m       raise TypeError(\"Operation names are strings (or similar), not %s.\" %\n\u001b[1;32m   3923\u001b[0m                       type(name).__name__)\n\u001b[0;32m-> 3924\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_graph_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3926\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_operation_by_name_unsafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.2.0/envs/scikit_practice/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3795\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3796\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3798\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.2.0/envs/scikit_practice/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes_by_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3855\u001b[0m           raise KeyError(\"The name %s refers to an Operation not in the \"\n\u001b[0;32m-> 3856\u001b[0;31m                          \"graph.\" % repr(name))\n\u001b[0m\u001b[1;32m   3857\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes_by_name\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"The name 'mean_loss' refers to an Operation not in the graph.\""
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clas_re = DNN_Classifier()\n",
    "graph = clas_re.restore(\"Mnist-0to4\")\n",
    "preds = clas_re.predict(test_x_0to4)\n",
    "accuracy_score(preds, test_y_0to4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Rate With and Without Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0905 20:35:56.957761 4513576384 deprecation.py:323] From <ipython-input-4-99b76afb2362>:32: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, score 0.974837, loss 0.055582\n",
      "epoch 20, score 0.985948, loss 0.001568\n",
      "epoch 40, score 0.987908, loss 0.279178\n",
      "epoch 60, score 0.985294, loss 0.000009\n",
      "epoch 80, score 0.991176, loss 0.000143\n",
      "epoch 100, score 0.988562, loss 0.000001\n",
      "No progress for 30 epoches.\n",
      "Reverting back to epoch 73                     with 0.000000 score\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNN_Classifier(activation=<function get_leaky_relu.<locals>.<lambda> at 0x1a2790ba60>,\n",
       "        batch_norm_momentum=0.98, batch_size=50, dropout_rate=None,\n",
       "        learning_rate=0.01, n_hidden_layers=2, n_neurons=20, n_outputs=5,\n",
       "        optimizer=<class 'tensorflow.python.training.adam.AdamOptimizer'>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = DNN_Classifier(2, 20, 5, activation=get_leaky_relu(0.01), batch_norm_momentum=.98)\n",
    "classifier.fit(train_x_0to4, train_y_0to4, val_x_0to4, val_y_0to4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Best Parameters Using RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-07 19:43:08.124990\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "[CV] n_outputs=5, n_neurons=100, n_hidden_layers=5, batch_size=100, activation=<function relu at 0x11aa4aa60> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/devbhadurkhadka/.pyenv/versions/anaconda3-5.2.0/envs/scikit_practice/lib/python3.6/site-packages/sklearn/model_selection/_search.py:584: DeprecationWarning: \"fit_params\" as a constructor argument was deprecated in version 0.19 and will be removed in version 0.21. Pass fit parameters to the \"fit\" method instead.\n",
      "  '\"fit\" method instead.', DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, score 0.969608, loss 0.209717\n",
      "epoch 20, score 0.984967, loss 0.033849\n",
      "epoch 40, score 0.981373, loss 0.004538\n",
      "epoch 60, score 0.985621, loss 0.011594\n",
      "epoch 80, score 0.982353, loss 0.019855\n",
      "epoch 100, score 0.968301, loss 0.060462\n",
      "No progress for 30 epoches.\n",
      "Reverting back to epoch 74                     with 0.000000 score\n",
      "validation score: %f 0.9858372\n",
      "validation score: %f 0.9993463\n",
      "[CV]  n_outputs=5, n_neurons=100, n_hidden_layers=5, batch_size=100, activation=<function relu at 0x11aa4aa60>, score=0.9858372211456299, total= 1.7min\n",
      "[CV] n_outputs=5, n_neurons=100, n_hidden_layers=5, batch_size=100, activation=<function relu at 0x11aa4aa60> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, score 0.971569, loss 0.021749\n",
      "epoch 20, score 0.986601, loss 0.016834\n",
      "epoch 40, score 0.985948, loss 0.000045\n",
      "epoch 60, score 0.982680, loss 0.001042\n",
      "No progress for 30 epoches.\n",
      "Reverting back to epoch 42                     with 0.000003 score\n",
      "validation score: %f 0.9868177\n",
      "validation score: %f 0.9988015\n",
      "[CV]  n_outputs=5, n_neurons=100, n_hidden_layers=5, batch_size=100, activation=<function relu at 0x11aa4aa60>, score=0.9868177175521851, total= 1.2min\n",
      "[CV] n_outputs=5, n_neurons=100, n_hidden_layers=5, batch_size=100, activation=<function relu at 0x11aa4aa60> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  2.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, score 0.973529, loss 0.121668\n",
      "epoch 20, score 0.990196, loss 0.133423\n",
      "epoch 40, score 0.989869, loss 0.013864\n",
      "epoch 60, score 0.986928, loss 0.055011\n",
      "No progress for 30 epoches.\n",
      "Reverting back to epoch 38                     with 0.000000 score\n",
      "validation score: %f 0.9881238\n",
      "validation score: %f 0.9986927\n",
      "[CV]  n_outputs=5, n_neurons=100, n_hidden_layers=5, batch_size=100, activation=<function relu at 0x11aa4aa60>, score=0.9881237745285034, total= 1.1min\n",
      "[CV] n_outputs=5, n_neurons=100, n_hidden_layers=5, batch_size=300, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c485f6d90> \n",
      "epoch 0, score 0.974510, loss 0.048159\n",
      "epoch 20, score 0.984314, loss 0.011303\n",
      "epoch 40, score 0.982026, loss 0.006482\n",
      "epoch 60, score 0.989542, loss 0.000003\n",
      "epoch 80, score 0.989542, loss 0.000000\n",
      "epoch 100, score 0.988562, loss 0.000000\n",
      "No progress for 30 epoches.\n",
      "Reverting back to epoch 71                     with 0.000000 score\n",
      "validation score: %f 0.9896503\n",
      "validation score: %f 0.9999455\n",
      "[CV]  n_outputs=5, n_neurons=100, n_hidden_layers=5, batch_size=300, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c485f6d90>, score=0.989650309085846, total= 1.3min\n",
      "[CV] n_outputs=5, n_neurons=100, n_hidden_layers=5, batch_size=300, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c485f6d90> \n",
      "epoch 0, score 0.974510, loss 0.065966\n",
      "epoch 20, score 0.987582, loss 0.001721\n",
      "epoch 40, score 0.986274, loss 0.008122\n",
      "epoch 60, score 0.988889, loss 0.000000\n",
      "epoch 80, score 0.988889, loss 0.000000\n",
      "epoch 100, score 0.988562, loss 0.000000\n",
      "epoch 120, score 0.988562, loss 0.000000\n",
      "epoch 140, score 0.988562, loss 0.000000\n",
      "No progress for 30 epoches.\n",
      "Reverting back to epoch 121                     with 0.000000 score\n",
      "validation score: %f 0.9889966\n",
      "validation score: %f 1.0\n",
      "[CV]  n_outputs=5, n_neurons=100, n_hidden_layers=5, batch_size=300, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c485f6d90>, score=0.9889966249465942, total= 1.9min\n",
      "[CV] n_outputs=5, n_neurons=100, n_hidden_layers=5, batch_size=300, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c485f6d90> \n",
      "epoch 0, score 0.974183, loss 0.059277\n",
      "epoch 20, score 0.988562, loss 0.001217\n",
      "epoch 40, score 0.987255, loss 0.000397\n",
      "epoch 60, score 0.986601, loss 0.000120\n",
      "epoch 80, score 0.986928, loss 0.000017\n",
      "epoch 100, score 0.986274, loss 0.000001\n",
      "No progress for 30 epoches.\n",
      "Reverting back to epoch 86                     with 0.000000 score\n",
      "validation score: %f 0.98866856\n",
      "validation score: %f 1.0\n",
      "[CV]  n_outputs=5, n_neurons=100, n_hidden_layers=5, batch_size=300, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c485f6d90>, score=0.9886685609817505, total= 1.5min\n",
      "[CV] n_outputs=5, n_neurons=100, n_hidden_layers=5, batch_size=300, activation=<function elu at 0x11ab252f0> \n",
      "epoch 0, score 0.970915, loss 0.094406\n",
      "epoch 20, score 0.985621, loss 0.005086\n",
      "epoch 40, score 0.989542, loss 0.002296\n",
      "epoch 60, score 0.985948, loss 0.000256\n",
      "epoch 80, score 0.986928, loss 0.000022\n",
      "epoch 100, score 0.986928, loss 0.000000\n",
      "epoch 120, score 0.987255, loss 0.000001\n",
      "epoch 140, score 0.987255, loss 0.000000\n",
      "epoch 160, score 0.987255, loss 0.000000\n",
      "No progress for 30 epoches.\n",
      "Reverting back to epoch 145                     with 0.000000 score\n",
      "validation score: %f 0.9894324\n",
      "validation score: %f 1.0\n",
      "[CV]  n_outputs=5, n_neurons=100, n_hidden_layers=5, batch_size=300, activation=<function elu at 0x11ab252f0>, score=0.9894323945045471, total= 2.1min\n",
      "[CV] n_outputs=5, n_neurons=100, n_hidden_layers=5, batch_size=300, activation=<function elu at 0x11ab252f0> \n",
      "epoch 0, score 0.967320, loss 0.098214\n",
      "epoch 20, score 0.987255, loss 0.009146\n",
      "epoch 40, score 0.985294, loss 0.001208\n",
      "epoch 60, score 0.988562, loss 0.004961\n",
      "No progress for 30 epoches.\n",
      "Reverting back to epoch 48                     with 0.000000 score\n",
      "validation score: %f 0.988234\n",
      "validation score: %f 0.9997821\n",
      "[CV]  n_outputs=5, n_neurons=100, n_hidden_layers=5, batch_size=300, activation=<function elu at 0x11ab252f0>, score=0.9882339835166931, total=  57.6s\n",
      "[CV] n_outputs=5, n_neurons=100, n_hidden_layers=5, batch_size=300, activation=<function elu at 0x11ab252f0> \n",
      "epoch 0, score 0.972549, loss 0.126564\n",
      "epoch 20, score 0.988235, loss 0.001142\n",
      "epoch 40, score 0.984967, loss 0.000712\n",
      "epoch 60, score 0.985621, loss 0.000787\n",
      "epoch 80, score 0.984641, loss 0.001366\n",
      "No progress for 30 epoches.\n",
      "Reverting back to epoch 56                     with 0.000004 score\n",
      "validation score: %f 0.9887775\n",
      "validation score: %f 0.9996187\n",
      "[CV]  n_outputs=5, n_neurons=100, n_hidden_layers=5, batch_size=300, activation=<function elu at 0x11ab252f0>, score=0.9887775182723999, total= 1.1min\n",
      "[CV] n_outputs=5, n_neurons=100, n_hidden_layers=5, batch_size=300, activation=<function relu at 0x11aa4aa60> \n",
      "epoch 0, score 0.973856, loss 0.107475\n",
      "epoch 20, score 0.988235, loss 0.022323\n",
      "epoch 40, score 0.985294, loss 0.041120\n",
      "epoch 60, score 0.984314, loss 0.005697\n",
      "epoch 80, score 0.989216, loss 0.000000\n",
      "epoch 100, score 0.988562, loss 0.000001\n",
      "epoch 120, score 0.988235, loss 0.000001\n",
      "epoch 140, score 0.988235, loss 0.000000\n",
      "epoch 160, score 0.987582, loss 0.000000\n",
      "epoch 180, score 0.987255, loss 0.000000\n",
      "epoch 200, score 0.987255, loss 0.000000\n",
      "epoch 220, score 0.987255, loss 0.000000\n",
      "No progress for 30 epoches.\n",
      "Reverting back to epoch 190                     with 0.000000 score\n",
      "validation score: %f 0.988234\n",
      "validation score: %f 1.0\n",
      "[CV]  n_outputs=5, n_neurons=100, n_hidden_layers=5, batch_size=300, activation=<function relu at 0x11aa4aa60>, score=0.9882339835166931, total= 2.3min\n",
      "[CV] n_outputs=5, n_neurons=100, n_hidden_layers=5, batch_size=300, activation=<function relu at 0x11aa4aa60> \n",
      "epoch 0, score 0.977451, loss 0.064408\n",
      "epoch 20, score 0.988889, loss 0.001494\n",
      "epoch 40, score 0.987255, loss 0.016684\n",
      "epoch 60, score 0.989542, loss 0.000001\n",
      "epoch 80, score 0.989869, loss 0.000414\n",
      "epoch 100, score 0.986601, loss 0.000342\n",
      "epoch 120, score 0.987582, loss 0.007575\n",
      "No progress for 30 epoches.\n",
      "Reverting back to epoch 94                     with 0.000000 score\n",
      "validation score: %f 0.98638195\n",
      "validation score: %f 0.9999455\n",
      "[CV]  n_outputs=5, n_neurons=100, n_hidden_layers=5, batch_size=300, activation=<function relu at 0x11aa4aa60>, score=0.9863819479942322, total= 1.3min\n",
      "[CV] n_outputs=5, n_neurons=100, n_hidden_layers=5, batch_size=300, activation=<function relu at 0x11aa4aa60> \n",
      "epoch 0, score 0.976471, loss 0.060553\n",
      "epoch 20, score 0.985621, loss 0.004817\n",
      "epoch 40, score 0.987582, loss 0.000111\n",
      "epoch 60, score 0.987255, loss 0.000002\n",
      "epoch 80, score 0.987582, loss 0.000001\n",
      "epoch 100, score 0.987255, loss 0.000000\n",
      "epoch 120, score 0.987582, loss 0.000000\n",
      "epoch 140, score 0.987908, loss 0.000000\n",
      "No progress for 30 epoches.\n",
      "Reverting back to epoch 116                     with 0.000000 score\n",
      "validation score: %f 0.9887775\n",
      "validation score: %f 1.0\n",
      "[CV]  n_outputs=5, n_neurons=100, n_hidden_layers=5, batch_size=300, activation=<function relu at 0x11aa4aa60>, score=0.9887775182723999, total= 1.5min\n",
      "[CV] n_outputs=5, n_neurons=100, n_hidden_layers=5, batch_size=100, activation=<function elu at 0x11ab252f0> \n",
      "epoch 0, score 0.974837, loss 0.058056\n",
      "epoch 20, score 0.980719, loss 0.009022\n",
      "epoch 40, score 0.964052, loss 0.174088\n",
      "epoch 60, score 0.980392, loss 0.005847\n",
      "No progress for 30 epoches.\n",
      "Reverting back to epoch 32                     with 0.000024 score\n",
      "validation score: %f 0.9872535\n",
      "validation score: %f 0.9985292\n",
      "[CV]  n_outputs=5, n_neurons=100, n_hidden_layers=5, batch_size=100, activation=<function elu at 0x11ab252f0>, score=0.9872534871101379, total= 1.2min\n",
      "[CV] n_outputs=5, n_neurons=100, n_hidden_layers=5, batch_size=100, activation=<function elu at 0x11ab252f0> \n",
      "epoch 0, score 0.971569, loss 0.123486\n",
      "epoch 20, score 0.990196, loss 0.000599\n",
      "epoch 40, score 0.988235, loss 0.015165\n",
      "epoch 60, score 0.983333, loss 0.001285\n",
      "epoch 80, score 0.563725, loss 0.848648\n",
      "No progress for 30 epoches.\n",
      "Reverting back to epoch 64                     with 0.000086 score\n",
      "validation score: %f 0.98540145\n",
      "validation score: %f 0.99749416\n",
      "[CV]  n_outputs=5, n_neurons=100, n_hidden_layers=5, batch_size=100, activation=<function elu at 0x11ab252f0>, score=0.985401451587677, total= 1.6min\n",
      "[CV] n_outputs=5, n_neurons=100, n_hidden_layers=5, batch_size=100, activation=<function elu at 0x11ab252f0> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, score 0.974183, loss 0.072922\n",
      "epoch 20, score 0.988235, loss 0.000854\n",
      "epoch 40, score 0.957516, loss 0.331167\n",
      "No progress for 30 epoches.\n",
      "Reverting back to epoch 11                     with 0.000185 score\n",
      "validation score: %f 0.9834387\n",
      "validation score: %f 0.9941715\n",
      "[CV]  n_outputs=5, n_neurons=100, n_hidden_layers=5, batch_size=100, activation=<function elu at 0x11ab252f0>, score=0.9834386706352234, total=  47.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed: 21.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, score 0.978105, loss 0.083818\n",
      "epoch 20, score 0.982026, loss 0.070610\n",
      "epoch 40, score 0.988235, loss 0.011768\n",
      "epoch 60, score 0.988235, loss 0.010102\n",
      "epoch 80, score 0.990850, loss 0.000005\n",
      "epoch 100, score 0.991830, loss 0.000000\n",
      "epoch 120, score 0.991503, loss 0.000000\n",
      "No progress for 30 epoches.\n",
      "Reverting back to epoch 94                     with 0.000000 score\n",
      "2019-09-07 20:06:49.660282\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from datetime import datetime\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "\n",
    "print(datetime.today())\n",
    "params_dist = {\n",
    "    \"n_neurons\":[100],\n",
    "    \"n_hidden_layers\": [5],\n",
    "    \"n_outputs\": [5],\n",
    "    \"activation\": [tf.nn.relu, get_leaky_relu(0.01), tf.nn.elu],\n",
    "    \"batch_size\": [100,300]\n",
    "}\n",
    "\n",
    "classifier = DNN_Classifier()\n",
    "fit_params = {\"x_val\": val_x_0to4, \"y_val\": val_y_0to4}\n",
    "rand_search = RandomizedSearchCV(classifier, params_dist, n_iter=5, cv=3,\n",
    "                                 n_jobs=1, fit_params=fit_params, verbose=3)\n",
    "rand_search.fit(train_x_0to4, train_y_0to4)\n",
    "\n",
    "print(datetime.today())\n",
    "\n",
    "rand_search.best_estimator_.save(\"Mnist-0to4-best1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_outputs': 5,\n",
       " 'n_neurons': 100,\n",
       " 'n_hidden_layers': 5,\n",
       " 'batch_size': 300,\n",
       " 'activation': <function __main__.get_leaky_relu.<locals>.<lambda>(z, name=None)>}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-05 20:41:14.616038\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "[CV] n_outputs=5, n_neurons=150, n_hidden_layers=5, batch_size=100, batch_norm_momentum=0.99, activation=<function elu at 0x1a21e9a1e0> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/devbhadurkhadka/.pyenv/versions/anaconda3-5.2.0/envs/scikit_practice/lib/python3.6/site-packages/sklearn/model_selection/_search.py:584: DeprecationWarning: \"fit_params\" as a constructor argument was deprecated in version 0.19 and will be removed in version 0.21. Pass fit parameters to the \"fit\" method instead.\n",
      "  '\"fit\" method instead.', DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, score 0.978431, loss 0.051807\n",
      "epoch 20, score 0.985948, loss 0.004050\n",
      "epoch 40, score 0.988235, loss 0.000353\n",
      "epoch 60, score 0.984967, loss 0.000186\n",
      "No progress for 30 epoches.\n",
      "Reverting back to epoch 43                     with 0.000006 score\n",
      "validation score: %f 0.99172026\n",
      "validation score: %f 0.99983656\n",
      "[CV]  n_outputs=5, n_neurons=150, n_hidden_layers=5, batch_size=100, batch_norm_momentum=0.99, activation=<function elu at 0x1a21e9a1e0>, score=0.9917202591896057, total= 2.3min\n",
      "[CV] n_outputs=5, n_neurons=150, n_hidden_layers=5, batch_size=100, batch_norm_momentum=0.99, activation=<function elu at 0x1a21e9a1e0> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, score 0.977124, loss 0.091709\n",
      "epoch 20, score 0.985294, loss 0.085647\n",
      "epoch 40, score 0.990850, loss 0.000743\n",
      "epoch 60, score 0.988562, loss 0.000008\n",
      "epoch 80, score 0.990523, loss 0.000060\n",
      "epoch 100, score 0.989869, loss 0.000008\n",
      "epoch 120, score 0.989869, loss 0.000022\n",
      "epoch 140, score 0.989542, loss 0.000008\n",
      "epoch 160, score 0.988562, loss 0.000001\n",
      "epoch 180, score 0.991176, loss 0.000002\n",
      "No progress for 30 epoches.\n",
      "Reverting back to epoch 159                     with 0.000000 score\n",
      "validation score: %f 0.9922649\n",
      "validation score: %f 0.9999455\n",
      "[CV]  n_outputs=5, n_neurons=150, n_hidden_layers=5, batch_size=100, batch_norm_momentum=0.99, activation=<function elu at 0x1a21e9a1e0>, score=0.9922649264335632, total= 5.8min\n",
      "[CV] n_outputs=5, n_neurons=150, n_hidden_layers=5, batch_size=100, batch_norm_momentum=0.99, activation=<function elu at 0x1a21e9a1e0> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  8.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, score 0.974510, loss 0.039386\n",
      "epoch 20, score 0.987582, loss 0.002258\n",
      "epoch 40, score 0.988889, loss 0.000175\n",
      "epoch 60, score 0.985948, loss 0.000104\n",
      "No progress for 30 epoches.\n",
      "Reverting back to epoch 31                     with 0.000031 score\n",
      "validation score: %f 0.9895402\n",
      "validation score: %f 0.99891055\n",
      "[CV]  n_outputs=5, n_neurons=150, n_hidden_layers=5, batch_size=100, batch_norm_momentum=0.99, activation=<function elu at 0x1a21e9a1e0>, score=0.9895402193069458, total= 1.9min\n",
      "[CV] n_outputs=5, n_neurons=150, n_hidden_layers=5, batch_size=100, batch_norm_momentum=0.98, activation=<function relu at 0x1a21e48950> \n",
      "epoch 0, score 0.972222, loss 0.120286\n",
      "epoch 20, score 0.989216, loss 0.008831\n",
      "epoch 40, score 0.979739, loss 0.053936\n",
      "epoch 60, score 0.991503, loss 0.004413\n",
      "epoch 80, score 0.990523, loss 0.000083\n",
      "epoch 100, score 0.989542, loss 0.001401\n",
      "No progress for 30 epoches.\n",
      "Reverting back to epoch 71                     with 0.000002 score\n",
      "validation score: %f 0.9913934\n",
      "validation score: %f 0.99961865\n",
      "[CV]  n_outputs=5, n_neurons=150, n_hidden_layers=5, batch_size=100, batch_norm_momentum=0.98, activation=<function relu at 0x1a21e48950>, score=0.9913933873176575, total= 2.9min\n",
      "[CV] n_outputs=5, n_neurons=150, n_hidden_layers=5, batch_size=100, batch_norm_momentum=0.98, activation=<function relu at 0x1a21e48950> \n",
      "epoch 0, score 0.978105, loss 0.086481\n",
      "epoch 20, score 0.987582, loss 0.001435\n",
      "epoch 40, score 0.987255, loss 0.000282\n",
      "epoch 60, score 0.990196, loss 0.000385\n",
      "epoch 80, score 0.987582, loss 0.003349\n",
      "epoch 100, score 0.987908, loss 0.000099\n",
      "epoch 120, score 0.988889, loss 0.000261\n",
      "epoch 140, score 0.987582, loss 0.000643\n",
      "No progress for 30 epoches.\n",
      "Reverting back to epoch 111                     with 0.000000 score\n",
      "validation score: %f 0.99117553\n",
      "validation score: %f 0.99983656\n",
      "[CV]  n_outputs=5, n_neurons=150, n_hidden_layers=5, batch_size=100, batch_norm_momentum=0.98, activation=<function relu at 0x1a21e48950>, score=0.9911755323410034, total= 4.0min\n",
      "[CV] n_outputs=5, n_neurons=150, n_hidden_layers=5, batch_size=100, batch_norm_momentum=0.98, activation=<function relu at 0x1a21e48950> \n",
      "epoch 0, score 0.974510, loss 0.019313\n",
      "epoch 20, score 0.988235, loss 0.002121\n",
      "epoch 40, score 0.985948, loss 0.006221\n",
      "epoch 60, score 0.989869, loss 0.000006\n",
      "epoch 80, score 0.989216, loss 0.000024\n",
      "No progress for 30 epoches.\n",
      "Reverting back to epoch 57                     with 0.000006 score\n",
      "validation score: %f 0.990085\n",
      "validation score: %f 0.9993463\n",
      "[CV]  n_outputs=5, n_neurons=150, n_hidden_layers=5, batch_size=100, batch_norm_momentum=0.98, activation=<function relu at 0x1a21e48950>, score=0.9900850057601929, total= 2.6min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=100, batch_norm_momentum=0.98, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1a2887fae8> \n",
      "epoch 0, score 0.969935, loss 0.041208\n",
      "epoch 20, score 0.986274, loss 0.000233\n",
      "epoch 40, score 0.980719, loss 0.001008\n",
      "epoch 60, score 0.988889, loss 0.000013\n",
      "epoch 80, score 0.988889, loss 0.000048\n",
      "No progress for 30 epoches.\n",
      "Reverting back to epoch 61                     with 0.000001 score\n",
      "validation score: %f 0.99019504\n",
      "validation score: %f 0.99983656\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=100, batch_norm_momentum=0.98, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1a2887fae8>, score=0.9901950359344482, total= 2.8min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=100, batch_norm_momentum=0.98, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1a2887fae8> \n",
      "epoch 0, score 0.977778, loss 0.082243\n",
      "epoch 20, score 0.982680, loss 0.006948\n",
      "epoch 40, score 0.987582, loss 0.002451\n",
      "No progress for 30 epoches.\n",
      "Reverting back to epoch 28                     with 0.000007 score\n",
      "validation score: %f 0.9907397\n",
      "validation score: %f 0.9997821\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=100, batch_norm_momentum=0.98, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1a2887fae8>, score=0.9907397031784058, total= 1.8min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=100, batch_norm_momentum=0.98, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1a2887fae8> \n",
      "epoch 0, score 0.982026, loss 0.006043\n",
      "epoch 20, score 0.983987, loss 0.004127\n",
      "epoch 40, score 0.987255, loss 0.000274\n",
      "epoch 60, score 0.987582, loss 0.002121\n",
      "epoch 80, score 0.990523, loss 0.000093\n",
      "epoch 100, score 0.990523, loss 0.000118\n",
      "No progress for 30 epoches.\n",
      "Reverting back to epoch 85                     with 0.000001 score\n",
      "validation score: %f 0.98899543\n",
      "validation score: %f 0.9980935\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=100, batch_norm_momentum=0.98, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1a2887fae8>, score=0.9889954328536987, total= 3.4min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=80, batch_norm_momentum=0.99, activation=<function elu at 0x1a21e9a1e0> \n",
      "epoch 0, score 0.972876, loss 0.078991\n",
      "epoch 20, score 0.989216, loss 0.000473\n",
      "epoch 40, score 0.982353, loss 0.002546\n",
      "epoch 60, score 0.990523, loss 0.000022\n",
      "epoch 80, score 0.990850, loss 0.000003\n",
      "epoch 100, score 0.986274, loss 0.000215\n",
      "epoch 120, score 0.988235, loss 0.000014\n",
      "epoch 140, score 0.991830, loss 0.000006\n",
      "epoch 160, score 0.990196, loss 0.000219\n",
      "epoch 180, score 0.989542, loss 0.000003\n",
      "epoch 200, score 0.989542, loss 0.000000\n",
      "epoch 220, score 0.987255, loss 0.000015\n",
      "No progress for 30 epoches.\n",
      "Reverting back to epoch 199                     with 0.000000 score\n",
      "validation score: %f 0.9931365\n",
      "validation score: %f 1.0\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=80, batch_norm_momentum=0.99, activation=<function elu at 0x1a21e9a1e0>, score=0.9931365251541138, total= 7.3min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=80, batch_norm_momentum=0.99, activation=<function elu at 0x1a21e9a1e0> \n",
      "epoch 0, score 0.977451, loss 0.058001\n",
      "epoch 20, score 0.981046, loss 0.000490\n",
      "epoch 40, score 0.984967, loss 0.000074\n",
      "epoch 60, score 0.993137, loss 0.000006\n",
      "epoch 80, score 0.988235, loss 0.000240\n",
      "No progress for 30 epoches.\n",
      "Reverting back to epoch 60                     with 0.000006 score\n",
      "validation score: %f 0.9913934\n",
      "validation score: %f 0.9999455\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=80, batch_norm_momentum=0.99, activation=<function elu at 0x1a21e9a1e0>, score=0.9913933873176575, total= 2.7min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=80, batch_norm_momentum=0.99, activation=<function elu at 0x1a21e9a1e0> \n",
      "epoch 0, score 0.973856, loss 0.086854\n",
      "epoch 20, score 0.984967, loss 0.018201\n",
      "epoch 40, score 0.986274, loss 0.000323\n",
      "epoch 60, score 0.986274, loss 0.000069\n",
      "epoch 80, score 0.988562, loss 0.000483\n",
      "epoch 100, score 0.989542, loss 0.000005\n",
      "epoch 120, score 0.991176, loss 0.001616\n",
      "No progress for 30 epoches.\n",
      "Reverting back to epoch 104                     with 0.000001 score\n",
      "validation score: %f 0.9917193\n",
      "validation score: %f 0.9997821\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=80, batch_norm_momentum=0.99, activation=<function elu at 0x1a21e9a1e0>, score=0.9917193055152893, total= 3.9min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=100, batch_norm_momentum=0.99, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1a2887fae8> \n",
      "epoch 0, score 0.965033, loss 0.050281\n",
      "epoch 20, score 0.979085, loss 0.005913\n",
      "epoch 40, score 0.989869, loss 0.001328\n",
      "epoch 60, score 0.990523, loss 0.000582\n",
      "No progress for 30 epoches.\n",
      "Reverting back to epoch 48                     with 0.000021 score\n",
      "validation score: %f 0.9920471\n",
      "validation score: %f 0.99961865\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=100, batch_norm_momentum=0.99, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1a2887fae8>, score=0.9920470714569092, total= 2.4min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=100, batch_norm_momentum=0.99, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1a2887fae8> \n",
      "epoch 0, score 0.973529, loss 0.209846\n",
      "epoch 20, score 0.972876, loss 0.005261\n",
      "epoch 40, score 0.984967, loss 0.000048\n",
      "epoch 60, score 0.988235, loss 0.000740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80, score 0.988562, loss 0.000094\n",
      "epoch 100, score 0.989216, loss 0.000007\n",
      "epoch 120, score 0.988889, loss 0.000014\n",
      "epoch 140, score 0.990523, loss 0.000010\n",
      "No progress for 30 epoches.\n",
      "Reverting back to epoch 127                     with 0.000001 score\n",
      "validation score: %f 0.98932344\n",
      "validation score: %f 0.9997276\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=100, batch_norm_momentum=0.99, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1a2887fae8>, score=0.9893234372138977, total= 4.5min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=100, batch_norm_momentum=0.99, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1a2887fae8> \n",
      "epoch 0, score 0.972222, loss 0.056430\n",
      "epoch 20, score 0.982353, loss 0.075404\n",
      "epoch 40, score 0.987255, loss 0.002217\n",
      "epoch 60, score 0.988235, loss 0.000754\n",
      "epoch 80, score 0.990523, loss 0.000039\n",
      "epoch 100, score 0.988235, loss 0.000009\n",
      "epoch 120, score 0.991503, loss 0.001018\n",
      "No progress for 30 epoches.\n",
      "Reverting back to epoch 90                     with 0.000001 score\n",
      "validation score: %f 0.9926999\n",
      "validation score: %f 0.9999455\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=100, batch_norm_momentum=0.99, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1a2887fae8>, score=0.992699921131134, total= 3.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed: 51.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, score 0.975163, loss 0.038283\n",
      "epoch 20, score 0.987582, loss 0.000351\n",
      "epoch 40, score 0.990850, loss 0.015891\n",
      "epoch 60, score 0.990523, loss 0.000135\n",
      "epoch 80, score 0.989542, loss 0.000012\n",
      "epoch 100, score 0.991503, loss 0.000063\n",
      "epoch 120, score 0.990850, loss 0.000051\n",
      "epoch 140, score 0.992157, loss 0.000166\n",
      "epoch 160, score 0.992157, loss 0.000002\n",
      "epoch 180, score 0.991830, loss 0.000003\n",
      "epoch 200, score 0.991176, loss 0.000013\n",
      "epoch 220, score 0.991830, loss 0.000029\n",
      "No progress for 30 epoches.\n",
      "Reverting back to epoch 205                     with 0.000000 score\n",
      "2019-09-05 21:43:21.864585\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'test accuracy: 0.992411'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "print(datetime.today())\n",
    "params_dist = {\n",
    "    \"n_neurons\":[120,150],\n",
    "    \"n_hidden_layers\": [5],\n",
    "    \"n_outputs\": [5],\n",
    "    \"batch_norm_momentum\": [.98, .99],\n",
    "    \"activation\": [tf.nn.relu, get_leaky_relu(0.01), tf.nn.elu],\n",
    "    \"batch_size\": [80,100]\n",
    "}\n",
    "\n",
    "classifier = DNN_Classifier()\n",
    "fit_params = {\"x_val\": val_x_0to4, \"y_val\": val_y_0to4}\n",
    "rand_search = RandomizedSearchCV(classifier, params_dist, n_iter=5, cv=3,\n",
    "                                 n_jobs=1, fit_params=fit_params, verbose=3)\n",
    "rand_search.fit(train_x_0to4, train_y_0to4)\n",
    "\n",
    "print(datetime.today())\n",
    "\n",
    "rand_search.best_estimator_.save(\"Mnist-0to4-best_batch_norm\")\n",
    "\n",
    "preds = rand_search.best_estimator_.predict(test_x_0to4)\n",
    "\"test accuracy: %f\"%accuracy_score(preds, test_y_0to4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test accuracy: 0.995524'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\"test accuracy: %f\"%accuracy_score(preds, test_y_0to4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_outputs': 5,\n",
       " 'n_neurons': 120,\n",
       " 'n_hidden_layers': 5,\n",
       " 'batch_size': 100,\n",
       " 'batch_norm_momentum': 0.98,\n",
       " 'activation': <function __main__.get_leaky_relu.<locals>.<lambda>(z, name=None)>}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-23 21:00:30.181454\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.6, batch_size=50, activation=<function elu at 0x1a20af31e0> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/devbhadurkhadka/.pyenv/versions/anaconda3-5.2.0/envs/scikit_practice/lib/python3.6/site-packages/sklearn/model_selection/_search.py:584: DeprecationWarning: \"fit_params\" as a constructor argument was deprecated in version 0.19 and will be removed in version 0.21. Pass fit parameters to the \"fit\" method instead.\n",
      "  '\"fit\" method instead.', DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, score 0.200654, loss 2.511327\n",
      "epoch 50, score 0.191503, loss 1.673325\n",
      "epoch 100, score 0.223529, loss 1.784896\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 10                     with 0.370261 score\n",
      "validation score: %f 0.363983\n",
      "validation score: %f 0.37920138\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.6, batch_size=50, activation=<function elu at 0x1a20af31e0>, score=0.36398300528526306, total= 3.2min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.6, batch_size=50, activation=<function elu at 0x1a20af31e0> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, score 0.191503, loss 1.979267\n",
      "epoch 50, score 0.191503, loss 1.710331\n",
      "epoch 100, score 0.191830, loss 1.617060\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 6                     with 0.223529 score\n",
      "validation score: %f 0.22083016\n",
      "validation score: %f 0.21958926\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.6, batch_size=50, activation=<function elu at 0x1a20af31e0>, score=0.22083015739917755, total= 3.6min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.6, batch_size=50, activation=<function elu at 0x1a20af31e0> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  6.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, score 0.200327, loss 1.459546\n",
      "epoch 50, score 0.200327, loss 1.686456\n",
      "epoch 100, score 0.192810, loss 1.711437\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 5                     with 0.223529 score\n",
      "validation score: %f 0.22368708\n",
      "validation score: %f 0.21816102\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.6, batch_size=50, activation=<function elu at 0x1a20af31e0>, score=0.223687082529068, total= 3.3min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.2, batch_size=100, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c3852d7b8> \n",
      "epoch 0, score 0.933333, loss 0.397353\n",
      "epoch 50, score 0.951307, loss 0.435087\n",
      "epoch 100, score 0.928105, loss 0.497548\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 6                     with 0.972549 score\n",
      "validation score: %f 0.9633947\n",
      "validation score: %f 0.97042\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.2, batch_size=100, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c3852d7b8>, score=0.9633947014808655, total= 2.8min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.2, batch_size=100, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c3852d7b8> \n",
      "epoch 0, score 0.921569, loss 0.541837\n",
      "epoch 50, score 0.957843, loss 0.247198\n",
      "epoch 100, score 0.954575, loss 0.401142\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 13                     with 0.980719 score\n",
      "validation score: %f 0.9778843\n",
      "validation score: %f 0.97859126\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.2, batch_size=100, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c3852d7b8>, score=0.9778842926025391, total= 2.9min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.2, batch_size=100, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c3852d7b8> \n",
      "epoch 0, score 0.933007, loss 0.471347\n",
      "epoch 50, score 0.799346, loss 0.802404\n",
      "epoch 100, score 0.875817, loss 0.431196\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 10                     with 0.981046 score\n",
      "validation score: %f 0.9761386\n",
      "validation score: %f 0.98305917\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.2, batch_size=100, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c3852d7b8>, score=0.9761385917663574, total= 2.8min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.2, batch_size=100, activation=<function elu at 0x1a20af31e0> \n",
      "epoch 0, score 0.941503, loss 0.617818\n",
      "epoch 50, score 0.200327, loss 1.626830\n",
      "epoch 100, score 0.223529, loss 1.547778\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 14                     with 0.979739 score\n",
      "validation score: %f 0.9736355\n",
      "validation score: %f 0.9811516\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.2, batch_size=100, activation=<function elu at 0x1a20af31e0>, score=0.9736354947090149, total= 3.0min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.2, batch_size=100, activation=<function elu at 0x1a20af31e0> \n",
      "epoch 0, score 0.914052, loss 0.679885\n",
      "epoch 50, score 0.405556, loss 1.093436\n",
      "epoch 100, score 0.223529, loss 1.633742\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 7                     with 0.971242 score\n",
      "validation score: %f 0.9694956\n",
      "validation score: %f 0.97254455\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.2, batch_size=100, activation=<function elu at 0x1a20af31e0>, score=0.9694955945014954, total= 2.9min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.2, batch_size=100, activation=<function elu at 0x1a20af31e0> \n",
      "epoch 0, score 0.924837, loss 0.512203\n",
      "epoch 50, score 0.193137, loss 1.523156\n",
      "epoch 100, score 0.223529, loss 1.611071\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 14                     with 0.980065 score\n",
      "validation score: %f 0.97472215\n",
      "validation score: %f 0.98153394\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.2, batch_size=100, activation=<function elu at 0x1a20af31e0>, score=0.974722146987915, total= 3.0min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.6, batch_size=80, activation=<function relu at 0x1a20a79950> \n",
      "epoch 0, score 0.200327, loss 1.817046\n",
      "epoch 50, score 0.192810, loss 1.605816\n",
      "epoch 100, score 0.223529, loss 1.612167\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 9                     with 0.384314 score\n",
      "validation score: %f 0.37814575\n",
      "validation score: %f 0.3874816\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.6, batch_size=80, activation=<function relu at 0x1a20a79950>, score=0.3781457543373108, total= 3.0min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.6, batch_size=80, activation=<function relu at 0x1a20a79950> \n",
      "epoch 0, score 0.192484, loss 1.709757\n",
      "epoch 50, score 0.191830, loss 6.695802\n",
      "epoch 100, score 0.223529, loss 1.625347\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 11                     with 0.372549 score\n",
      "validation score: %f 0.36997494\n",
      "validation score: %f 0.37250096\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.6, batch_size=80, activation=<function relu at 0x1a20a79950>, score=0.36997494101524353, total= 3.1min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.6, batch_size=80, activation=<function relu at 0x1a20a79950> \n",
      "epoch 0, score 0.223529, loss 1.655535\n",
      "epoch 50, score 0.192810, loss 1.612964\n",
      "epoch 100, score 0.223529, loss 1.590082\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 13                     with 0.335621 score\n",
      "validation score: %f 0.33002833\n",
      "validation score: %f 0.32160366\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.6, batch_size=80, activation=<function relu at 0x1a20a79950>, score=0.33002832531929016, total= 3.2min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.4, batch_size=50, activation=<function relu at 0x1a20a79950> \n",
      "epoch 0, score 0.506863, loss 1.296286\n",
      "epoch 50, score 0.223529, loss 1.611830\n",
      "epoch 100, score 0.223529, loss 1.611283\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 3                     with 0.582353 score\n",
      "validation score: %f 0.5708683\n",
      "validation score: %f 0.58789563\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.4, batch_size=50, activation=<function relu at 0x1a20a79950>, score=0.5708683133125305, total= 3.2min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.4, batch_size=50, activation=<function relu at 0x1a20a79950> \n",
      "epoch 0, score 0.540196, loss 1.373591\n",
      "epoch 50, score 0.411438, loss 1.295681\n",
      "epoch 100, score 0.389542, loss 1.559840\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 5                     with 0.593464 score\n",
      "validation score: %f 0.5815448\n",
      "validation score: %f 0.5834287\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.4, batch_size=50, activation=<function relu at 0x1a20a79950>, score=0.581544816493988, total= 3.5min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.4, batch_size=50, activation=<function relu at 0x1a20a79950> \n",
      "epoch 0, score 0.529412, loss 1.236342\n",
      "epoch 50, score 0.223529, loss 1.608894\n",
      "epoch 100, score 0.223529, loss 1.610012\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 7                     with 0.599346 score\n",
      "validation score: %f 0.58683807\n",
      "validation score: %f 0.58590263\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.4, batch_size=50, activation=<function relu at 0x1a20a79950>, score=0.5868380665779114, total= 3.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed: 47.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, score 0.951961, loss 0.394898\n",
      "epoch 50, score 0.191830, loss 1.617283\n",
      "epoch 100, score 0.192810, loss 1.657724\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 6                     with 0.976471 score\n",
      "2019-08-23 21:52:37.437255\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9778166958552248"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(datetime.today())\n",
    "params_dist = {\n",
    "    \"n_neurons\":[120],\n",
    "    \"n_hidden_layers\": [5],\n",
    "    \"n_outputs\": [5],\n",
    "    \"dropout_rate\": [.6, .4, .2],\n",
    "    \"activation\": [tf.nn.relu, get_leaky_relu(0.01), tf.nn.elu],\n",
    "    \"batch_size\": [50,80,100]\n",
    "}\n",
    "\n",
    "classifier = DNN_Classifier()\n",
    "fit_params = {\"x_val\": val_x_0to4, \"y_val\": val_y_0to4}\n",
    "rand_search3 = RandomizedSearchCV(classifier, params_dist, n_iter=5, cv=3,\n",
    "                                 n_jobs=1, fit_params=fit_params, verbose=3)\n",
    "rand_search3.fit(train_x_0to4, train_y_0to4)\n",
    "\n",
    "print(datetime.today())\n",
    "\n",
    "rand_search3.best_estimator_.save(\"Mnist-0to4-best_dropoutdsf\")\n",
    "\n",
    "preds = rand_search3.best_estimator_.predict(test_x_0to4)\n",
    "accuracy_score(preds, test_y_0to4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_outputs': 5,\n",
       " 'n_neurons': 120,\n",
       " 'n_hidden_layers': 5,\n",
       " 'dropout_rate': 0.2,\n",
       " 'batch_size': 100,\n",
       " 'activation': <function tensorflow.python.ops.gen_nn_ops.elu(features, name=None)>}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_search3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
