{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "- Tune the hyperparameters using cross-validation and see what precision you can achieve. \n",
    "- Now try adding Batch Normalization and compare the learning curves: is it converging faster than before? Does it produce a better model? \n",
    "- Is the model overfitting the training set? Try adding dropout to every layer and try again. Does it help?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frame\n",
    "- Create predictor class \"DNN_Classifier\" using DNN with hyper parameters\n",
    "    - implement __init__, fit, predict and predict_prob\n",
    "    - Fit will use class DNN_Helper with methods create_graph(which will create tensor flow graph) and train_dnn (which will train dnn with given hyper-parameters)\n",
    "    - create_graph will use hyper-parameters like number of neurons, activation function, optimizer class, learning rate etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Notes About Graph and Session\n",
    "- Tensorflow computations are represented as graph which indicates operands, operations and their dependencies.\n",
    "- Graph is run within context of Session which stores current state of the computations\n",
    "- When creating a tensor or an operation it is automatically added to default graph\n",
    "- We can also create another graph and make it default using \n",
    "       \n",
    "       ``` python\n",
    "           with graph.as_default():\n",
    "               # add tensors and operations\n",
    "       ```\n",
    "       \n",
    "- No computation are run until it is run inside the context of a session\n",
    "    \n",
    "    ``` python\n",
    "        # The session will use current default graph\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(op)\n",
    "        \n",
    "        # The session will use graph sent as parameter\n",
    "        with tf.Session(graph=graph) as sess:\n",
    "            sess.run(op)\n",
    "        \n",
    "    ```\n",
    "    \n",
    "- ```tf.train.Saver``` can be used to save session and restore it latter when needed\n",
    "    \n",
    "    ``` python\n",
    "    saver.save(session, path)\n",
    "    saver.restore(session,path)\n",
    "    ```\n",
    "    \n",
    "- Graph must be created before restoring the session. To restore graph also from the checkpoint file use following code which will restore graph as default graph\n",
    "``` python\n",
    "    meta_importer = tf.train.import_meta_graph(checkpoint_path+\".meta\")\n",
    "    \n",
    "    # Then restore session\n",
    "    sess = tf.Session()\n",
    "    meta_importer.restore(sess, checkpoint_path)\n",
    "```\n",
    "\n",
    "- When restoring graph from meta file our tensor and operation variables are not assigned automatically. So we need to find them in graph by name or other way and assign it to variables to easily use them. Some functions are\n",
    "  - ```graph.get_tensor_by_name(\"x:0\")``` here 0 indicates 1st output of operation x\n",
    "  - ```graph.get_operation_by_name(\"is_training\")```\n",
    "  - ```graph.collections``` is list of collection names\n",
    "  - ```tf.get_collection(collection_name)``` will give all variables in a collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MINST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/devbhadurkhadka/.pyenv/versions/anaconda3-5.2.0/envs/scikit_practice/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(-1, 28*28)\n",
    "x_test = x_test.reshape(-1, 28*28)\n",
    "\n",
    "train_indxes_0to4 = y_train<5\n",
    "train_x_0to4 = x_train[train_indxes_0to4]\n",
    "train_y_0to4 = y_train[train_indxes_0to4]\n",
    "\n",
    "test_indxes_0to4 = y_test<5\n",
    "test_x_0to4 = x_test[test_indxes_0to4]\n",
    "test_y_0to4 = y_test[test_indxes_0to4]\n",
    "\n",
    "\n",
    "\n",
    "(train_x_0to4, val_x_0to4, train_y_0to4, val_y_0to4) = \\\n",
    "    train_test_split(train_x_0to4, train_y_0to4, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import variance_scaling_initializer as he_initializer\n",
    "from tensorflow.nn import sparse_softmax_cross_entropy_with_logits as softmax_xentropy\n",
    "from tensorflow.layers import dense\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_leaky_relu(alpha):\n",
    "    return lambda z, name=None: tf.maximum(alpha*z,z, name=name)\n",
    "    \n",
    "\n",
    "def get_connected_layers(x, n_hidden_layers, n_neurons, n_ouputs, activation=tf.nn.elu,\n",
    "                                   batch_norm_momentum=None, dropout_rate=None, is_training=None):\n",
    "    \n",
    "\n",
    "    initializer = he_initializer()\n",
    "    \n",
    "    with tf.name_scope(\"DNN\"):\n",
    "        inputs = x\n",
    "        for l in range(n_hidden_layers):\n",
    "            if dropout_rate is not None:\n",
    "                ## this function will set inputs to zero with dropout rate probability\n",
    "                ## and divides remaining inputs with dropout rate\n",
    "                inputs = tf.layers.dropout(inputs, dropout_rate, training=is_training, \n",
    "                                  name=(\"dropout%d\"%l))\n",
    "                \n",
    "            inputs = tf.layers.dense(inputs, n_neurons, kernel_initializer=initializer,\n",
    "                           name=\"hidden%d\"%(l+1), activation=activation)\n",
    "            \n",
    "            if batch_norm_momentum is not None:\n",
    "                inputs = tf.layers.batch_normalization(inputs, momentum=batch_norm_momentum,\n",
    "                                training=is_training)\n",
    "            \n",
    "            inputs = activation(inputs, name=\"hiden%d_out\"%(l+1))\n",
    "            \n",
    "        output = tf.layers.dense(inputs, n_ouputs, name=\"output\")\n",
    "        \n",
    "    return output\n",
    "        \n",
    "\n",
    "\n",
    "def get_softmax_xentropy_loss(logits,y):\n",
    "    with tf.name_scope(\"loss\"):\n",
    "        xentropy = softmax_xentropy(labels=y, logits=logits)\n",
    "        return tf.reduce_mean(xentropy, name=\"mean_loss\")\n",
    "\n",
    "def get_optimizer_op(optimizer, loss, learning_rate=0.01):\n",
    "    with tf.name_scope(\"train\"):\n",
    "        optimizer =  optimizer(learning_rate=learning_rate)\n",
    "        optimizer_op = optimizer.minimize(loss, name=\"optimizer_op\")\n",
    "    return optimizer_op\n",
    "\n",
    "def get_validation_score(logits,y):\n",
    "    with tf.name_scope(\"validation\"):\n",
    "        preds = tf.nn.in_top_k(logits,y,1)\n",
    "        return tf.reduce_mean(tf.cast(preds, dtype=np.float32), name=\"validation_score\")\n",
    "    \n",
    "def get_batch(x,y,batch_size):\n",
    "    n_batches = len(y)//batch_size + 1\n",
    "    for i in range(n_batches):\n",
    "        indxes = np.random.choice(len(y), size=batch_size, replace=False)\n",
    "        yield x[indxes], y[indxes]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Classifier Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imp import reload\n",
    "# import my_libs\n",
    "# reload(my_libs.tf_graph_saver)\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from my_libs.tf_graph_saver import ScalerGraphSaver2\n",
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "\n",
    "\n",
    "class DNN_Classifier(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_hidden_layers=None, n_neurons=None, n_outputs=None, \n",
    "                 activation=tf.nn.elu, optimizer=tf.train.AdamOptimizer,  learning_rate=0.01, \n",
    "                 batch_norm_momentum=None, batch_size=50, dropout_rate=None):\n",
    "        self.n_hidden_layers = n_hidden_layers\n",
    "        self.n_neurons = n_neurons\n",
    "        self.learning_rate = learning_rate\n",
    "        self.activation = activation\n",
    "        self.optimizer = optimizer\n",
    "        self.batch_norm_momentum = batch_norm_momentum\n",
    "        self.batch_size = batch_size\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.n_outputs = n_outputs\n",
    "        self._session = None\n",
    "        \n",
    "        \n",
    "    def _create_graph(self):                      \n",
    "        \n",
    "        tf.reset_default_graph()\n",
    "        self._graph = tf.Graph()\n",
    "        with self._graph.as_default():\n",
    "        \n",
    "            self._x = tf.placeholder(shape=(None, 28*28), dtype=np.float32,name=\"x\")\n",
    "            self._y = tf.placeholder(shape=(None), dtype=np.int32,name=\"y\")\n",
    "\n",
    "            self._is_training = tf.placeholder_with_default(False,shape=(), name=\"is_training\")\n",
    "\n",
    "\n",
    "            self._dnn = get_connected_layers(self._x, self.n_hidden_layers, self.n_neurons, \n",
    "                                       self.n_outputs, activation=self.activation, \n",
    "                                       batch_norm_momentum=self.batch_norm_momentum, \n",
    "                                       dropout_rate=self.dropout_rate, is_training=self._is_training)\n",
    "            self._loss = get_softmax_xentropy_loss(self._dnn, self._y)\n",
    "            self._optimizer_op = get_optimizer_op(self.optimizer, self._loss, \n",
    "                                                  self.learning_rate)\n",
    "            self._validation_score = get_validation_score(self._dnn, self._y)\n",
    "\n",
    "            self._y_proba = tf.nn.softmax(self._dnn, name=\"y_proba\")\n",
    "\n",
    "            self._batch_norm_update_ops = self._graph.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "            self._saver = tf.train.Saver()\n",
    "            self._init = tf.global_variables_initializer()\n",
    "            \n",
    "        \n",
    "    def _save_params(self):\n",
    "        with self._graph.as_default():\n",
    "            global_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "            \n",
    "        vars_n_values = {global_var.op.name:value for global_var, value in \\\n",
    "                 zip(global_vars,self._session.run(global_vars))}\n",
    "        self._saved_params =  vars_n_values\n",
    "        \n",
    "    \n",
    "    def _restore_params(self):\n",
    "        var_names = list(self._saved_params.keys())\n",
    "        \n",
    "        ## get assign operations for all variables\n",
    "        assign_ops = {var_name:self._graph.get_operation_by_name(\"%s/Assign\"%var_name) \n",
    "                      for var_name in var_names}\n",
    "        ## get initialization values of all variables\n",
    "        init_values = {var_name: assign_op.inputs[1]  for var_name, assign_op \n",
    "                       in assign_ops.items()}\n",
    "        \n",
    "        ## get feed_dict for all values\n",
    "        feed_dict = {init_values[var_name]:self._saved_params[var_name] \n",
    "                     for var_name in var_names}\n",
    "        \n",
    "        \n",
    "        self._session.run(assign_ops, feed_dict=feed_dict)\n",
    "        \n",
    "    \n",
    "    def fit(self,x,y,x_val,y_val):\n",
    "        n_epoches = 500\n",
    "        max_epoches_wo_progress = 100\n",
    "        \n",
    "        self._create_graph()\n",
    "        \n",
    "        best_score=0\n",
    "        best_epoch=0\n",
    "        if self._session: self._session.close()\n",
    "        with tf.Session(graph=self._graph).as_default() as sess:\n",
    "            self._session = sess\n",
    "            sess.run(self._init)\n",
    "            \n",
    "            graph_saver = ScalerGraphSaver2(\"DNN_GridSearch\")\n",
    "            loss_summary = graph_saver.get_summary_op(\"loss\", self._loss)\n",
    "            score_summary = graph_saver.get_summary_op(\"accuracy_score\", self._validation_score)\n",
    "            \n",
    "            with graph_saver:\n",
    "        \n",
    "                for epoch in range(n_epoches):\n",
    "                    for batch_x, batch_y in get_batch(x,y,self.batch_size):\n",
    "                        ops = [self._loss, loss_summary, self._optimizer_op]\n",
    "                        if self._batch_norm_update_ops is not None:\n",
    "                            ops.append(self._batch_norm_update_ops)\n",
    "\n",
    "                        results = sess.run(ops , feed_dict={self._x:batch_x, self._y:batch_y, \n",
    "                                               self._is_training:True})\n",
    "                        loss = results[0]\n",
    "                        loss_summary_text = results[1]\n",
    "\n",
    "\n",
    "\n",
    "                    score, score_summary_text = sess.run([self._validation_score, score_summary], \n",
    "                                     feed_dict={self._x:x_val, self._y:y_val})\n",
    "                    graph_saver.log_summary(loss_summary_text, epoch)\n",
    "                    graph_saver.log_summary(score_summary_text, epoch)\n",
    "                    \n",
    "                    if epoch%50 == 0:\n",
    "                        print(\"epoch %d, score %f, loss %f\"%(epoch, score, loss))\n",
    "\n",
    "                    if score > best_score:\n",
    "                        best_score = score\n",
    "                        best_epoch = epoch\n",
    "                        self._save_params()\n",
    "                    elif (epoch - best_epoch)>max_epoches_wo_progress:\n",
    "                        print(\"No progress for %d epoches.\"%max_epoches_wo_progress)\n",
    "                        break\n",
    "                \n",
    "            self._restore_params()\n",
    "            print(\"Reverting back to epoch %d \\\n",
    "                    with %f score\" %(best_epoch, best_score))\n",
    "            self._score = best_score \n",
    "            return self\n",
    "            \n",
    "                    \n",
    "    \n",
    "    def predict_proba(self,x):\n",
    "        if self._session is None:\n",
    "            raise NotFittedError(\"%s is not fitted yet\" \\\n",
    "                                                    %self.__class__.__name__)\n",
    "        \n",
    "        return self._session.run(self._y_proba, feed_dict={self._x:x, \n",
    "                                                           self._is_training:False})\n",
    "            \n",
    "    \n",
    "    def predict(self,x):\n",
    "        return np.argmax(self.predict_proba(x), axis=1)\n",
    "    \n",
    "    def score(self, x_val=None, y_val=None):\n",
    "        \n",
    "        score=self._session.run(self._validation_score, \n",
    "                             feed_dict={self._x:x_val, self._y:y_val})\n",
    "        print(\"validation score: %f\", score)\n",
    "        return score\n",
    "    \n",
    "    def _get_save_path(self, name):\n",
    "        return \"tf_checkpoints/%s\"%name\n",
    "    \n",
    "    def save(self,name):\n",
    "        self._saver.save(self._session, self._get_save_path(name))\n",
    "    \n",
    "    def restore(self, name):\n",
    "        imported_meta = tf.train.import_meta_graph(\"%s.meta\"%self._get_save_path(name))\n",
    "        graph = tf.get_default_graph()\n",
    "        self._x = graph.get_tensor_by_name(\"x:0\")\n",
    "        self._y = graph.get_tensor_by_name(\"y:0\")\n",
    "        self._loss = graph.get_operation_by_name(\"mean_loss\")\n",
    "        \n",
    "        self._validation_score = graph.get_tensor_by_name(\"validation/validation_score:0\")\n",
    "        self._y_proba = graph.get_tensor_by_name(\"y_proba:0\")\n",
    "        self._is_training = graph.get_tensor_by_name(\"is_training:0\")\n",
    "        self._session = tf.Session(graph=graph)\n",
    "        imported_meta.restore(self._session, self._get_save_path(name))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, score 0.927778, loss 0.590107\n",
      "epoch 50, score 0.958170, loss 0.096847\n",
      "epoch 100, score 0.979085, loss 0.025066\n",
      "epoch 150, score 0.977124, loss 0.000035\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 67                     with 0.982026 score\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNN_Classifier(activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c39591048>,\n",
       "        batch_norm_momentum=None, batch_size=50, dropout_rate=None,\n",
       "        learning_rate=0.01, n_hidden_layers=2, n_neurons=20, n_outputs=5,\n",
       "        optimizer=<class 'tensorflow.python.training.adam.AdamOptimizer'>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = DNN_Classifier(2, 20, 5, activation=get_leaky_relu(0.01))\n",
    "classifier.fit(train_x_0to4, train_y_0to4, val_x_0to4, val_y_0to4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save(\"Mnist-0to4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9820976843743919"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clas_re = DNN_Classifier()\n",
    "graph = clas_re.restore(\"Mnist-0to4\")\n",
    "preds = clas_re.predict(test_x_0to4)\n",
    "accuracy_score(preds, test_y_0to4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Rate With and Without Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, score 0.978431, loss 0.035092\n",
      "epoch 50, score 0.987582, loss 0.001325\n",
      "epoch 100, score 0.989542, loss 0.000238\n",
      "epoch 150, score 0.986274, loss 0.000030\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 88                     with 0.991830 score\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNN_Classifier(activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c395919d8>,\n",
       "        batch_norm_momentum=0.98, batch_size=50, dropout_rate=None,\n",
       "        learning_rate=0.01, n_hidden_layers=2, n_neurons=20, n_outputs=5,\n",
       "        optimizer=<class 'tensorflow.python.training.adam.AdamOptimizer'>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = DNN_Classifier(2, 20, 5, activation=get_leaky_relu(0.01), batch_norm_momentum=.98)\n",
    "classifier.fit(train_x_0to4, train_y_0to4, val_x_0to4, val_y_0to4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Best Parameters Using RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-23 17:38:25.754383\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "[CV] n_outputs=5, n_neurons=100, n_hidden_layers=5, batch_size=50, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c360bb268> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/devbhadurkhadka/.pyenv/versions/anaconda3-5.2.0/envs/scikit_practice/lib/python3.6/site-packages/sklearn/model_selection/_search.py:584: DeprecationWarning: \"fit_params\" as a constructor argument was deprecated in version 0.19 and will be removed in version 0.21. Pass fit parameters to the \"fit\" method instead.\n",
      "  '\"fit\" method instead.', DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, score 0.950327\n",
      "epoch 50, score 0.861765\n",
      "epoch 100, score 0.895425\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 8                     with 0.981699 score\n",
      "validation score: %f 0.9753786\n",
      "validation score: %f 0.98343956\n",
      "[CV]  n_outputs=5, n_neurons=100, n_hidden_layers=5, batch_size=50, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c360bb268>, score=0.9753785729408264, total= 3.3min\n",
      "[CV] n_outputs=5, n_neurons=100, n_hidden_layers=5, batch_size=50, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c360bb268> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, score 0.965686\n",
      "epoch 50, score 0.953922\n",
      "epoch 100, score 0.385948\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 5                     with 0.980065 score\n",
      "validation score: %f 0.9723281\n",
      "validation score: %f 0.97804654\n",
      "[CV]  n_outputs=5, n_neurons=100, n_hidden_layers=5, batch_size=50, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c360bb268>, score=0.9723281264305115, total= 3.0min\n",
      "[CV] n_outputs=5, n_neurons=100, n_hidden_layers=5, batch_size=50, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c360bb268> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  6.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, score 0.942810\n",
      "epoch 50, score 0.594771\n",
      "epoch 100, score 0.931046\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 7                     with 0.980719 score\n",
      "validation score: %f 0.97494006\n",
      "validation score: %f 0.9826234\n",
      "[CV]  n_outputs=5, n_neurons=100, n_hidden_layers=5, batch_size=50, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c360bb268>, score=0.9749400615692139, total= 3.4min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=100, activation=<function relu at 0x1a20a79950> \n",
      "epoch 0, score 0.966340\n",
      "epoch 50, score 0.223529\n",
      "epoch 100, score 0.223529\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 26                     with 0.983660 score\n",
      "validation score: %f 0.98213315\n",
      "validation score: %f 0.9954241\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=100, activation=<function relu at 0x1a20a79950>, score=0.982133150100708, total= 2.1min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=100, activation=<function relu at 0x1a20a79950> \n",
      "epoch 0, score 0.963726\n",
      "epoch 50, score 0.223529\n",
      "epoch 100, score 0.223529\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 17                     with 0.984314 score\n",
      "validation score: %f 0.98147947\n",
      "validation score: %f 0.9931906\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=100, activation=<function relu at 0x1a20a79950>, score=0.9814794659614563, total= 1.8min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=100, activation=<function relu at 0x1a20a79950> \n",
      "epoch 0, score 0.950654\n",
      "epoch 50, score 0.223529\n",
      "epoch 100, score 0.223529\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 15                     with 0.983660 score\n",
      "validation score: %f 0.9784267\n",
      "validation score: %f 0.99128443\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=100, activation=<function relu at 0x1a20a79950>, score=0.9784266948699951, total= 1.8min\n",
      "[CV] n_outputs=5, n_neurons=80, n_hidden_layers=5, batch_size=50, activation=<function elu at 0x1a20af31e0> \n",
      "epoch 0, score 0.954575\n",
      "epoch 50, score 0.223529\n",
      "epoch 100, score 0.200327\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 7                     with 0.979085 score\n",
      "validation score: %f 0.97254604\n",
      "validation score: %f 0.98284036\n",
      "[CV]  n_outputs=5, n_neurons=80, n_hidden_layers=5, batch_size=50, activation=<function elu at 0x1a20af31e0>, score=0.9725460410118103, total= 2.1min\n",
      "[CV] n_outputs=5, n_neurons=80, n_hidden_layers=5, batch_size=50, activation=<function elu at 0x1a20af31e0> \n",
      "epoch 0, score 0.948693\n",
      "epoch 50, score 0.223529\n",
      "epoch 100, score 0.223529\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 2                     with 0.978431 score\n",
      "validation score: %f 0.97385335\n",
      "validation score: %f 0.9807703\n",
      "[CV]  n_outputs=5, n_neurons=80, n_hidden_layers=5, batch_size=50, activation=<function elu at 0x1a20af31e0>, score=0.973853349685669, total= 2.0min\n",
      "[CV] n_outputs=5, n_neurons=80, n_hidden_layers=5, batch_size=50, activation=<function elu at 0x1a20af31e0> \n",
      "epoch 0, score 0.957190\n",
      "epoch 50, score 0.191830\n",
      "epoch 100, score 0.191830\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 8                     with 0.980065 score\n",
      "validation score: %f 0.97602963\n",
      "validation score: %f 0.98507464\n",
      "[CV]  n_outputs=5, n_neurons=80, n_hidden_layers=5, batch_size=50, activation=<function elu at 0x1a20af31e0>, score=0.976029634475708, total= 2.4min\n",
      "[CV] n_outputs=5, n_neurons=80, n_hidden_layers=5, batch_size=50, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c360bb268> \n",
      "epoch 0, score 0.960458\n",
      "epoch 50, score 0.701961\n",
      "epoch 100, score 0.713072\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 6                     with 0.978431 score\n",
      "validation score: %f 0.9716745\n",
      "validation score: %f 0.9813695\n",
      "[CV]  n_outputs=5, n_neurons=80, n_hidden_layers=5, batch_size=50, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c360bb268>, score=0.9716745018959045, total= 2.6min\n",
      "[CV] n_outputs=5, n_neurons=80, n_hidden_layers=5, batch_size=50, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c360bb268> \n",
      "epoch 0, score 0.965359\n",
      "epoch 50, score 0.845425\n",
      "epoch 100, score 0.499346\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 5                     with 0.980065 score\n",
      "validation score: %f 0.9771217\n",
      "validation score: %f 0.98322165\n",
      "[CV]  n_outputs=5, n_neurons=80, n_hidden_layers=5, batch_size=50, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c360bb268>, score=0.9771217107772827, total= 2.6min\n",
      "[CV] n_outputs=5, n_neurons=80, n_hidden_layers=5, batch_size=50, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c360bb268> \n",
      "epoch 0, score 0.957190\n",
      "epoch 50, score 0.913072\n",
      "epoch 100, score 0.944118\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 7                     with 0.980719 score\n",
      "validation score: %f 0.975158\n",
      "validation score: %f 0.98344046\n",
      "[CV]  n_outputs=5, n_neurons=80, n_hidden_layers=5, batch_size=50, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c360bb268>, score=0.9751579761505127, total= 2.4min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=50, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c360bb268> \n",
      "epoch 0, score 0.955882\n",
      "epoch 50, score 0.470915\n",
      "epoch 100, score 0.877451\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 8                     with 0.977451 score\n",
      "validation score: %f 0.9741802\n",
      "validation score: %f 0.9832761\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=50, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c360bb268>, score=0.9741802215576172, total= 3.4min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=50, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c360bb268> \n",
      "epoch 0, score 0.956209\n",
      "epoch 50, score 0.887909\n",
      "epoch 100, score 0.813399\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 13                     with 0.984641 score\n",
      "validation score: %f 0.9806079\n",
      "validation score: %f 0.98747075\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=50, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c360bb268>, score=0.9806079268455505, total= 3.4min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=50, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c360bb268> \n",
      "epoch 0, score 0.966667\n",
      "epoch 50, score 0.472222\n",
      "epoch 100, score 0.436928\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 8                     with 0.977778 score\n",
      "validation score: %f 0.9711266\n",
      "validation score: %f 0.98017216\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=50, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c360bb268>, score=0.9711266160011292, total= 3.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed: 39.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, score 0.962092\n",
      "epoch 50, score 0.223529\n",
      "epoch 100, score 0.223529\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 15                     with 0.983987 score\n",
      "2019-08-23 18:21:32.915014\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from datetime import datetime\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "\n",
    "print(datetime.today())\n",
    "params_dist = {\n",
    "    \"n_neurons\":[80,100, 120],\n",
    "    \"n_hidden_layers\": [5],\n",
    "    \"n_outputs\": [5],\n",
    "    \"activation\": [tf.nn.relu, get_leaky_relu(0.01), tf.nn.elu],\n",
    "    \"batch_size\": [50,100]\n",
    "}\n",
    "\n",
    "classifier = DNN_Classifier()\n",
    "fit_params = {\"x_val\": val_x_0to4, \"y_val\": val_y_0to4}\n",
    "rand_search = RandomizedSearchCV(classifier, params_dist, n_iter=5, cv=3,\n",
    "                                 n_jobs=1, fit_params=fit_params, verbose=3)\n",
    "rand_search.fit(train_x_0to4, train_y_0to4)\n",
    "\n",
    "print(datetime.today())\n",
    "\n",
    "rand_search.best_estimator_.save(\"Mnist-0to4-best1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_outputs': 5,\n",
       " 'n_neurons': 120,\n",
       " 'n_hidden_layers': 5,\n",
       " 'batch_size': 100,\n",
       " 'activation': <function tensorflow.python.ops.gen_nn_ops.relu(features, name=None)>}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-23 22:01:10.884544\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "[CV] n_outputs=5, n_neurons=150, n_hidden_layers=5, batch_size=100, batch_norm_momentum=0.98, activation=<function elu at 0x1a20af31e0> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/devbhadurkhadka/.pyenv/versions/anaconda3-5.2.0/envs/scikit_practice/lib/python3.6/site-packages/sklearn/model_selection/_search.py:584: DeprecationWarning: \"fit_params\" as a constructor argument was deprecated in version 0.19 and will be removed in version 0.21. Pass fit parameters to the \"fit\" method instead.\n",
      "  '\"fit\" method instead.', DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, score 0.981373, loss 0.014723\n",
      "epoch 50, score 0.987908, loss 0.070573\n",
      "epoch 100, score 0.990850, loss 0.000025\n",
      "epoch 150, score 0.991503, loss 0.000003\n",
      "epoch 200, score 0.992484, loss 0.000005\n",
      "epoch 250, score 0.992157, loss 0.000001\n",
      "epoch 300, score 0.993464, loss 0.000026\n",
      "epoch 350, score 0.992484, loss 0.000001\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 279                     with 0.994444 score\n",
      "validation score: %f 0.9886698\n",
      "validation score: %f 0.9997276\n",
      "[CV]  n_outputs=5, n_neurons=150, n_hidden_layers=5, batch_size=100, batch_norm_momentum=0.98, activation=<function elu at 0x1a20af31e0>, score=0.9886698126792908, total=13.8min\n",
      "[CV] n_outputs=5, n_neurons=150, n_hidden_layers=5, batch_size=100, batch_norm_momentum=0.98, activation=<function elu at 0x1a20af31e0> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 13.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, score 0.979412, loss 0.154295\n",
      "epoch 50, score 0.992484, loss 0.000030\n",
      "epoch 100, score 0.993137, loss 0.000002\n",
      "epoch 150, score 0.988889, loss 0.022350\n",
      "epoch 200, score 0.992810, loss 0.000008\n",
      "epoch 250, score 0.988235, loss 0.005229\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 187                     with 0.994118 score\n",
      "validation score: %f 0.9907397\n",
      "validation score: %f 0.9994553\n",
      "[CV]  n_outputs=5, n_neurons=150, n_hidden_layers=5, batch_size=100, batch_norm_momentum=0.98, activation=<function elu at 0x1a20af31e0>, score=0.9907397031784058, total= 9.5min\n",
      "[CV] n_outputs=5, n_neurons=150, n_hidden_layers=5, batch_size=100, batch_norm_momentum=0.98, activation=<function elu at 0x1a20af31e0> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 23.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, score 0.983660, loss 0.087213\n",
      "epoch 50, score 0.989869, loss 0.012622\n",
      "epoch 100, score 0.993791, loss 0.000024\n",
      "epoch 150, score 0.993464, loss 0.000002\n",
      "epoch 200, score 0.992484, loss 0.000375\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 104                     with 0.994118 score\n",
      "validation score: %f 0.9928089\n",
      "validation score: %f 0.9999455\n",
      "[CV]  n_outputs=5, n_neurons=150, n_hidden_layers=5, batch_size=100, batch_norm_momentum=0.98, activation=<function elu at 0x1a20af31e0>, score=0.9928088784217834, total= 6.6min\n",
      "[CV] n_outputs=5, n_neurons=150, n_hidden_layers=5, batch_size=80, batch_norm_momentum=0.99, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c3681c488> \n",
      "epoch 0, score 0.966340, loss 0.023025\n",
      "epoch 50, score 0.990523, loss 0.039574\n",
      "epoch 100, score 0.991830, loss 0.001379\n",
      "epoch 150, score 0.989542, loss 0.000008\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 89                     with 0.994444 score\n",
      "validation score: %f 0.9904129\n",
      "validation score: %f 0.99989104\n",
      "[CV]  n_outputs=5, n_neurons=150, n_hidden_layers=5, batch_size=80, batch_norm_momentum=0.99, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c3681c488>, score=0.9904128909111023, total= 8.8min\n",
      "[CV] n_outputs=5, n_neurons=150, n_hidden_layers=5, batch_size=80, batch_norm_momentum=0.99, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c3681c488> \n",
      "epoch 0, score 0.970261, loss 0.038668\n",
      "epoch 50, score 0.990196, loss 0.000120\n",
      "epoch 100, score 0.992484, loss 0.000530\n",
      "epoch 150, score 0.993464, loss 0.000989\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 87                     with 0.995425 score\n",
      "validation score: %f 0.99150234\n",
      "validation score: %f 0.99983656\n",
      "[CV]  n_outputs=5, n_neurons=150, n_hidden_layers=5, batch_size=80, batch_norm_momentum=0.99, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c3681c488>, score=0.9915023446083069, total= 7.7min\n",
      "[CV] n_outputs=5, n_neurons=150, n_hidden_layers=5, batch_size=80, batch_norm_momentum=0.99, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c3681c488> \n",
      "epoch 0, score 0.978105, loss 0.098703\n",
      "epoch 50, score 0.991503, loss 0.014369\n",
      "epoch 100, score 0.992157, loss 0.000014\n",
      "epoch 150, score 0.992484, loss 0.000004\n",
      "epoch 200, score 0.994444, loss 0.000000\n",
      "epoch 250, score 0.993137, loss 0.000001\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 194                     with 0.995098 score\n",
      "validation score: %f 0.99259096\n",
      "validation score: %f 0.99950975\n",
      "[CV]  n_outputs=5, n_neurons=150, n_hidden_layers=5, batch_size=80, batch_norm_momentum=0.99, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c3681c488>, score=0.9925909638404846, total=254.1min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=80, batch_norm_momentum=0.98, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c3681c488> \n",
      "epoch 0, score 0.975817, loss 0.114647\n",
      "epoch 50, score 0.990523, loss 0.000754\n",
      "epoch 100, score 0.993791, loss 0.000028\n",
      "epoch 150, score 0.992157, loss 0.000376\n",
      "epoch 200, score 0.992810, loss 0.000012\n",
      "epoch 250, score 0.991176, loss 0.000765\n",
      "epoch 300, score 0.993137, loss 0.000003\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 210                     with 0.995098 score\n",
      "validation score: %f 0.99030393\n",
      "validation score: %f 1.0\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=80, batch_norm_momentum=0.98, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c3681c488>, score=0.9903039336204529, total=10.4min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=80, batch_norm_momentum=0.98, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c3681c488> \n",
      "epoch 0, score 0.976144, loss 0.202450\n",
      "epoch 50, score 0.990850, loss 0.002770\n",
      "epoch 100, score 0.989542, loss 0.000003\n",
      "epoch 150, score 0.991503, loss 0.000003\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 75                     with 0.993464 score\n",
      "validation score: %f 0.99117553\n",
      "validation score: %f 0.9996731\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=80, batch_norm_momentum=0.98, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c3681c488>, score=0.9911755323410034, total= 5.5min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=80, batch_norm_momentum=0.98, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c3681c488> \n",
      "epoch 0, score 0.976471, loss 0.190492\n",
      "epoch 50, score 0.991830, loss 0.061528\n",
      "epoch 100, score 0.990523, loss 0.000156\n",
      "epoch 150, score 0.991830, loss 0.000514\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 86                     with 0.994444 score\n",
      "validation score: %f 0.99259096\n",
      "validation score: %f 0.99983656\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=80, batch_norm_momentum=0.98, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c3681c488>, score=0.9925909638404846, total= 5.8min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=80, batch_norm_momentum=0.98, activation=<function relu at 0x1a20a79950> \n",
      "epoch 0, score 0.983987, loss 0.161392\n",
      "epoch 50, score 0.991830, loss 0.001243\n",
      "epoch 100, score 0.991176, loss 0.000055\n",
      "epoch 150, score 0.992484, loss 0.000001\n",
      "epoch 200, score 0.992157, loss 0.000799\n",
      "epoch 250, score 0.993137, loss 0.000000\n",
      "epoch 300, score 0.993791, loss 0.000002\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 247                     with 0.995752 score\n",
      "validation score: %f 0.99128443\n",
      "validation score: %f 0.9999455\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=80, batch_norm_momentum=0.98, activation=<function relu at 0x1a20a79950>, score=0.9912844300270081, total= 9.1min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=80, batch_norm_momentum=0.98, activation=<function relu at 0x1a20a79950> \n",
      "epoch 0, score 0.978758, loss 0.077412\n",
      "epoch 50, score 0.991830, loss 0.028664\n",
      "epoch 100, score 0.992810, loss 0.000074\n",
      "epoch 150, score 0.991176, loss 0.000048\n",
      "epoch 200, score 0.991830, loss 0.000005\n",
      "epoch 250, score 0.993464, loss 0.000000\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 192                     with 0.994444 score\n",
      "validation score: %f 0.99084866\n",
      "validation score: %f 0.9995642\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=80, batch_norm_momentum=0.98, activation=<function relu at 0x1a20a79950>, score=0.9908486604690552, total= 7.7min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=80, batch_norm_momentum=0.98, activation=<function relu at 0x1a20a79950> \n",
      "epoch 0, score 0.978758, loss 0.063189\n",
      "epoch 50, score 0.989216, loss 0.000532\n",
      "epoch 100, score 0.993137, loss 0.000523\n",
      "epoch 150, score 0.991176, loss 0.000000\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 60                     with 0.994118 score\n",
      "validation score: %f 0.9910656\n",
      "validation score: %f 0.99983656\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=80, batch_norm_momentum=0.98, activation=<function relu at 0x1a20a79950>, score=0.9910656213760376, total= 4.2min\n",
      "[CV] n_outputs=5, n_neurons=150, n_hidden_layers=5, batch_size=100, batch_norm_momentum=0.99, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c3681c488> \n",
      "epoch 0, score 0.958824, loss 0.089027\n",
      "epoch 50, score 0.988562, loss 0.000102\n",
      "epoch 100, score 0.992810, loss 0.000005\n",
      "epoch 150, score 0.994118, loss 0.000005\n",
      "epoch 200, score 0.991176, loss 0.000000\n",
      "epoch 250, score 0.991830, loss 0.000000\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 180                     with 0.994771 score\n",
      "validation score: %f 0.9904129\n",
      "validation score: %f 1.0\n",
      "[CV]  n_outputs=5, n_neurons=150, n_hidden_layers=5, batch_size=100, batch_norm_momentum=0.99, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c3681c488>, score=0.9904128909111023, total= 9.4min\n",
      "[CV] n_outputs=5, n_neurons=150, n_hidden_layers=5, batch_size=100, batch_norm_momentum=0.99, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c3681c488> \n",
      "epoch 0, score 0.961111, loss 0.073020\n",
      "epoch 50, score 0.989216, loss 0.006915\n",
      "epoch 100, score 0.993464, loss 0.000002\n",
      "epoch 150, score 0.991830, loss 0.000007\n",
      "epoch 200, score 0.993464, loss 0.000002\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 101                     with 0.994118 score\n",
      "validation score: %f 0.9907397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation score: %f 1.0\n",
      "[CV]  n_outputs=5, n_neurons=150, n_hidden_layers=5, batch_size=100, batch_norm_momentum=0.99, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c3681c488>, score=0.9907397031784058, total= 6.8min\n",
      "[CV] n_outputs=5, n_neurons=150, n_hidden_layers=5, batch_size=100, batch_norm_momentum=0.99, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c3681c488> \n",
      "epoch 0, score 0.982353, loss 0.154885\n",
      "epoch 50, score 0.989869, loss 0.001396\n",
      "epoch 100, score 0.992484, loss 0.000057\n",
      "epoch 150, score 0.993464, loss 0.000037\n",
      "epoch 200, score 0.992810, loss 0.000011\n",
      "epoch 250, score 0.992157, loss 0.000003\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 191                     with 0.995098 score\n",
      "validation score: %f 0.9928089\n",
      "validation score: %f 0.99983656\n",
      "[CV]  n_outputs=5, n_neurons=150, n_hidden_layers=5, batch_size=100, batch_norm_momentum=0.99, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c3681c488>, score=0.9928088784217834, total= 9.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed: 369.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, score 0.973529, loss 0.060896\n",
      "epoch 50, score 0.992157, loss 0.000057\n",
      "epoch 100, score 0.992810, loss 0.000002\n",
      "epoch 150, score 0.993791, loss 0.000002\n",
      "epoch 200, score 0.992484, loss 0.000000\n",
      "epoch 250, score 0.993791, loss 0.000000\n",
      "epoch 300, score 0.992484, loss 0.058179\n",
      "epoch 350, score 0.994771, loss 0.000000\n",
      "epoch 400, score 0.994118, loss 0.000000\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 308                     with 0.996732 score\n",
      "2019-08-24 04:34:12.752879\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'test accuracy: 0.996108'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(datetime.today())\n",
    "params_dist = {\n",
    "    \"n_neurons\":[120,150],\n",
    "    \"n_hidden_layers\": [5],\n",
    "    \"n_outputs\": [5],\n",
    "    \"batch_norm_momentum\": [.98, .99],\n",
    "    \"activation\": [tf.nn.relu, get_leaky_relu(0.01), tf.nn.elu],\n",
    "    \"batch_size\": [80,100]\n",
    "}\n",
    "\n",
    "classifier = DNN_Classifier()\n",
    "fit_params = {\"x_val\": val_x_0to4, \"y_val\": val_y_0to4}\n",
    "rand_search = RandomizedSearchCV(classifier, params_dist, n_iter=5, cv=3,\n",
    "                                 n_jobs=1, fit_params=fit_params, verbose=3)\n",
    "rand_search.fit(train_x_0to4, train_y_0to4)\n",
    "\n",
    "print(datetime.today())\n",
    "\n",
    "rand_search.best_estimator_.save(\"Mnist-0to4-best_batch_norm\")\n",
    "\n",
    "preds = rand_search.best_estimator_.predict(test_x_0to4)\n",
    "\"test accuracy: %f\"%accuracy_score(preds, test_y_0to4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_outputs': 5,\n",
       " 'n_neurons': 120,\n",
       " 'n_hidden_layers': 5,\n",
       " 'batch_size': 100,\n",
       " 'batch_norm_momentum': 0.99,\n",
       " 'activation': <function tensorflow.python.ops.gen_nn_ops.relu(features, name=None)>}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-23 21:00:30.181454\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.6, batch_size=50, activation=<function elu at 0x1a20af31e0> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/devbhadurkhadka/.pyenv/versions/anaconda3-5.2.0/envs/scikit_practice/lib/python3.6/site-packages/sklearn/model_selection/_search.py:584: DeprecationWarning: \"fit_params\" as a constructor argument was deprecated in version 0.19 and will be removed in version 0.21. Pass fit parameters to the \"fit\" method instead.\n",
      "  '\"fit\" method instead.', DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, score 0.200654, loss 2.511327\n",
      "epoch 50, score 0.191503, loss 1.673325\n",
      "epoch 100, score 0.223529, loss 1.784896\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 10                     with 0.370261 score\n",
      "validation score: %f 0.363983\n",
      "validation score: %f 0.37920138\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.6, batch_size=50, activation=<function elu at 0x1a20af31e0>, score=0.36398300528526306, total= 3.2min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.6, batch_size=50, activation=<function elu at 0x1a20af31e0> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, score 0.191503, loss 1.979267\n",
      "epoch 50, score 0.191503, loss 1.710331\n",
      "epoch 100, score 0.191830, loss 1.617060\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 6                     with 0.223529 score\n",
      "validation score: %f 0.22083016\n",
      "validation score: %f 0.21958926\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.6, batch_size=50, activation=<function elu at 0x1a20af31e0>, score=0.22083015739917755, total= 3.6min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.6, batch_size=50, activation=<function elu at 0x1a20af31e0> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  6.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, score 0.200327, loss 1.459546\n",
      "epoch 50, score 0.200327, loss 1.686456\n",
      "epoch 100, score 0.192810, loss 1.711437\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 5                     with 0.223529 score\n",
      "validation score: %f 0.22368708\n",
      "validation score: %f 0.21816102\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.6, batch_size=50, activation=<function elu at 0x1a20af31e0>, score=0.223687082529068, total= 3.3min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.2, batch_size=100, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c3852d7b8> \n",
      "epoch 0, score 0.933333, loss 0.397353\n",
      "epoch 50, score 0.951307, loss 0.435087\n",
      "epoch 100, score 0.928105, loss 0.497548\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 6                     with 0.972549 score\n",
      "validation score: %f 0.9633947\n",
      "validation score: %f 0.97042\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.2, batch_size=100, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c3852d7b8>, score=0.9633947014808655, total= 2.8min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.2, batch_size=100, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c3852d7b8> \n",
      "epoch 0, score 0.921569, loss 0.541837\n",
      "epoch 50, score 0.957843, loss 0.247198\n",
      "epoch 100, score 0.954575, loss 0.401142\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 13                     with 0.980719 score\n",
      "validation score: %f 0.9778843\n",
      "validation score: %f 0.97859126\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.2, batch_size=100, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c3852d7b8>, score=0.9778842926025391, total= 2.9min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.2, batch_size=100, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c3852d7b8> \n",
      "epoch 0, score 0.933007, loss 0.471347\n",
      "epoch 50, score 0.799346, loss 0.802404\n",
      "epoch 100, score 0.875817, loss 0.431196\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 10                     with 0.981046 score\n",
      "validation score: %f 0.9761386\n",
      "validation score: %f 0.98305917\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.2, batch_size=100, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c3852d7b8>, score=0.9761385917663574, total= 2.8min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.2, batch_size=100, activation=<function elu at 0x1a20af31e0> \n",
      "epoch 0, score 0.941503, loss 0.617818\n",
      "epoch 50, score 0.200327, loss 1.626830\n",
      "epoch 100, score 0.223529, loss 1.547778\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 14                     with 0.979739 score\n",
      "validation score: %f 0.9736355\n",
      "validation score: %f 0.9811516\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.2, batch_size=100, activation=<function elu at 0x1a20af31e0>, score=0.9736354947090149, total= 3.0min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.2, batch_size=100, activation=<function elu at 0x1a20af31e0> \n",
      "epoch 0, score 0.914052, loss 0.679885\n",
      "epoch 50, score 0.405556, loss 1.093436\n",
      "epoch 100, score 0.223529, loss 1.633742\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 7                     with 0.971242 score\n",
      "validation score: %f 0.9694956\n",
      "validation score: %f 0.97254455\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.2, batch_size=100, activation=<function elu at 0x1a20af31e0>, score=0.9694955945014954, total= 2.9min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.2, batch_size=100, activation=<function elu at 0x1a20af31e0> \n",
      "epoch 0, score 0.924837, loss 0.512203\n",
      "epoch 50, score 0.193137, loss 1.523156\n",
      "epoch 100, score 0.223529, loss 1.611071\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 14                     with 0.980065 score\n",
      "validation score: %f 0.97472215\n",
      "validation score: %f 0.98153394\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.2, batch_size=100, activation=<function elu at 0x1a20af31e0>, score=0.974722146987915, total= 3.0min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.6, batch_size=80, activation=<function relu at 0x1a20a79950> \n",
      "epoch 0, score 0.200327, loss 1.817046\n",
      "epoch 50, score 0.192810, loss 1.605816\n",
      "epoch 100, score 0.223529, loss 1.612167\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 9                     with 0.384314 score\n",
      "validation score: %f 0.37814575\n",
      "validation score: %f 0.3874816\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.6, batch_size=80, activation=<function relu at 0x1a20a79950>, score=0.3781457543373108, total= 3.0min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.6, batch_size=80, activation=<function relu at 0x1a20a79950> \n",
      "epoch 0, score 0.192484, loss 1.709757\n",
      "epoch 50, score 0.191830, loss 6.695802\n",
      "epoch 100, score 0.223529, loss 1.625347\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 11                     with 0.372549 score\n",
      "validation score: %f 0.36997494\n",
      "validation score: %f 0.37250096\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.6, batch_size=80, activation=<function relu at 0x1a20a79950>, score=0.36997494101524353, total= 3.1min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.6, batch_size=80, activation=<function relu at 0x1a20a79950> \n",
      "epoch 0, score 0.223529, loss 1.655535\n",
      "epoch 50, score 0.192810, loss 1.612964\n",
      "epoch 100, score 0.223529, loss 1.590082\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 13                     with 0.335621 score\n",
      "validation score: %f 0.33002833\n",
      "validation score: %f 0.32160366\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.6, batch_size=80, activation=<function relu at 0x1a20a79950>, score=0.33002832531929016, total= 3.2min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.4, batch_size=50, activation=<function relu at 0x1a20a79950> \n",
      "epoch 0, score 0.506863, loss 1.296286\n",
      "epoch 50, score 0.223529, loss 1.611830\n",
      "epoch 100, score 0.223529, loss 1.611283\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 3                     with 0.582353 score\n",
      "validation score: %f 0.5708683\n",
      "validation score: %f 0.58789563\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.4, batch_size=50, activation=<function relu at 0x1a20a79950>, score=0.5708683133125305, total= 3.2min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.4, batch_size=50, activation=<function relu at 0x1a20a79950> \n",
      "epoch 0, score 0.540196, loss 1.373591\n",
      "epoch 50, score 0.411438, loss 1.295681\n",
      "epoch 100, score 0.389542, loss 1.559840\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 5                     with 0.593464 score\n",
      "validation score: %f 0.5815448\n",
      "validation score: %f 0.5834287\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.4, batch_size=50, activation=<function relu at 0x1a20a79950>, score=0.581544816493988, total= 3.5min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.4, batch_size=50, activation=<function relu at 0x1a20a79950> \n",
      "epoch 0, score 0.529412, loss 1.236342\n",
      "epoch 50, score 0.223529, loss 1.608894\n",
      "epoch 100, score 0.223529, loss 1.610012\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 7                     with 0.599346 score\n",
      "validation score: %f 0.58683807\n",
      "validation score: %f 0.58590263\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.4, batch_size=50, activation=<function relu at 0x1a20a79950>, score=0.5868380665779114, total= 3.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed: 47.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, score 0.951961, loss 0.394898\n",
      "epoch 50, score 0.191830, loss 1.617283\n",
      "epoch 100, score 0.192810, loss 1.657724\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 6                     with 0.976471 score\n",
      "2019-08-23 21:52:37.437255\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9778166958552248"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(datetime.today())\n",
    "params_dist = {\n",
    "    \"n_neurons\":[120],\n",
    "    \"n_hidden_layers\": [5],\n",
    "    \"n_outputs\": [5],\n",
    "    \"dropout_rate\": [.6, .4, .2],\n",
    "    \"activation\": [tf.nn.relu, get_leaky_relu(0.01), tf.nn.elu],\n",
    "    \"batch_size\": [50,80,100]\n",
    "}\n",
    "\n",
    "classifier = DNN_Classifier()\n",
    "fit_params = {\"x_val\": val_x_0to4, \"y_val\": val_y_0to4}\n",
    "rand_search3 = RandomizedSearchCV(classifier, params_dist, n_iter=5, cv=3,\n",
    "                                 n_jobs=1, fit_params=fit_params, verbose=3)\n",
    "rand_search3.fit(train_x_0to4, train_y_0to4)\n",
    "\n",
    "print(datetime.today())\n",
    "\n",
    "rand_search3.best_estimator_.save(\"Mnist-0to4-best_dropoutdsf\")\n",
    "\n",
    "preds = rand_search3.best_estimator_.predict(test_x_0to4)\n",
    "accuracy_score(preds, test_y_0to4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_outputs': 5,\n",
       " 'n_neurons': 120,\n",
       " 'n_hidden_layers': 5,\n",
       " 'dropout_rate': 0.2,\n",
       " 'batch_size': 100,\n",
       " 'activation': <function tensorflow.python.ops.gen_nn_ops.elu(features, name=None)>}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_search3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
