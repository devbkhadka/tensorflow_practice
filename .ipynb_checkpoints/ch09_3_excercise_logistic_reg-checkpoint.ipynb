{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from os import path\n",
    "\n",
    "checkpoint_path = \"tf_checkpoints\"\n",
    "\n",
    "def save_checkpoint(step):\n",
    "    chk_path = \"{}/epoch.ckpt\".format(checkpoint_path)\n",
    "    sess = tf.get_default_session()\n",
    "    saver = tf.train.Saver(max_to_keep=2,)\n",
    "    saver.save(sess, chk_path)\n",
    "    \n",
    "    \n",
    "def restore_checkpoint(saver,sess):\n",
    "    chk_path = \"{}/epoch.ckpt\".format(checkpoint_path)\n",
    "#     sess = tf.get_default_session()\n",
    "    if path.exists(chk_path+\".index\"):\n",
    "#         saver = tf.train.Saver(max_to_keep=2,)\n",
    "        saver.restore(sess, chk_path)\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "    \n",
    "\n",
    "def logistic_regression_fit(features, targets):\n",
    "    '''\n",
    "    features: scaled feature including bais terms\n",
    "    targets: binary target 0 or 1\n",
    "    '''\n",
    "    n_epoches = 1000\n",
    "    lr = 0.01\n",
    "    ep = 1e-15\n",
    "    m,n = features.shape\n",
    "    X = tf.constant(features, dtype=tf.float32, name=\"X\")\n",
    "    y = tf.constant(targets, dtype=tf.float32, name=\"y\")\n",
    "    \n",
    "    theta = tf.Variable(tf.random_uniform((n,1),-1,1), dtype=tf.float32, name=\"theta\")\n",
    "#     cur_epoch = tf.Variable(0, dtype=tf.int32, name=\"cur_epoch\")\n",
    "    \n",
    "    with tf.name_scope(\"loss\") as scope:\n",
    "        lin_preds = tf.matmul(X, theta)\n",
    "        preds = tf.sigmoid(lin_preds)\n",
    "        log_loss = -tf.reduce_mean(y*tf.log(preds+ep)+(1-y)*tf.log(1-preds+ep))\n",
    "#         log_loss = tf.losses.log_loss(y,preds)\n",
    "    \n",
    "    with tf.name_scope(\"train\") as scope:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=lr)\n",
    "        train = optimizer.minimize(log_loss)\n",
    "        \n",
    "    with tf.name_scope(\"init\") as scope:\n",
    "        init = tf.global_variables_initializer()\n",
    "    \n",
    "    with tf.name_scope(\"save\") as scope:\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        if not restore_checkpoint(saver,sess):\n",
    "            sess.run(init)\n",
    "            \n",
    "        for epoch in range(n_epoches):\n",
    "            sess.run(train)\n",
    "            if epoch%100==0:\n",
    "                save_checkpoint(saver, sess,epoch)\n",
    "                print(\"log_loss: {}\".format(log_loss.eval()))\n",
    "            if epoch==500:\n",
    "                raise  Exception(\"Terminated to test saver\")\n",
    "        best_theta = theta.eval()\n",
    "    \n",
    "    return best_theta\n",
    "    \n",
    "\n",
    "def logistic_regression_predict(theta,X):\n",
    "    theta_tf = tf.constant(theta, dtype=tf.float32, name=\"theta\")\n",
    "    X_tf = tf.constant(X, dtype=tf.float32, name=\"X\")\n",
    "    lin_preds = tf.matmul(X_tf, theta_tf)\n",
    "    preds = tf.sigmoid(lin_preds)\n",
    "    with tf.Session() as sess:\n",
    "        predictions = preds.eval()\n",
    "    return predictions>=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "m,n = 3000,5\n",
    "X,y = make_moons(m, shuffle=True, noise=0.2)\n",
    "# X = StandardScaler().fit_transform(X)\n",
    "X = np.c_[np.ones((m,1)), X]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'saver restore'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_loss: 0.44614750146865845\n",
      "log_loss: 0.427530437707901\n",
      "log_loss: 0.4127029478549957\n",
      "log_loss: 0.4006727635860443\n",
      "log_loss: 0.39074820280075073\n",
      "log_loss: 0.38243818283081055\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Terminated to test saver",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-242-d27730b19848>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogistic_regression_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-241-36abcab71d39>\u001b[0m in \u001b[0;36mlogistic_regression_fit\u001b[0;34m(features, targets)\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"log_loss: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0;32mraise\u001b[0m  \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Terminated to test saver\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mbest_theta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Terminated to test saver"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "theta = logistic_regression_fit(X,y.reshape(-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8219406468822941"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       ...,\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "tn = -1\n",
    "preds = logistic_regression_predict(theta,X[:tn])\n",
    "display(accuracy_score(y[:tn], preds))\n",
    "np.c_[y[:tn], preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.train.Saver?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver.restore?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
