{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "- Tune the hyperparameters using cross-validation and see what precision you can achieve. \n",
    "- Now try adding Batch Normalization and compare the learning curves: is it converging faster than before? Does it produce a better model? \n",
    "- Is the model overfitting the training set? Try adding dropout to every layer and try again. Does it help?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frame\n",
    "- Create predictor class \"DNN_Classifier\" using DNN with hyper parameters\n",
    "    - implement __init__, fit, predict and predict_prob\n",
    "    - Fit will use class DNN_Helper with methods create_graph(which will create tensor flow graph) and train_dnn (which will train dnn with given hyper-parameters)\n",
    "    - create_graph will use hyper-parameters like number of neurons, activation function, optimizer class, learning rate etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Notes About Graph and Session\n",
    "- Tensorflow computations are represented as graph which indicates operands, operations and their dependencies.\n",
    "- Graph is run within context of Session which stores current state of the computations\n",
    "- When creating a tensor or an operation it is automatically added to default graph\n",
    "- We can also create another graph and make it default using \n",
    "       \n",
    "       ``` python\n",
    "           with graph.as_default():\n",
    "               # add tensors and operations\n",
    "       ```\n",
    "       \n",
    "- No computation are run until it is run inside the context of a session\n",
    "    \n",
    "    ``` python\n",
    "        # The session will use current default graph\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(op)\n",
    "        \n",
    "        # The session will use graph sent as parameter\n",
    "        with tf.Session(graph=graph) as sess:\n",
    "            sess.run(op)\n",
    "        \n",
    "    ```\n",
    "    \n",
    "- ```tf.train.Saver``` can be used to save session and restore it latter when needed\n",
    "    \n",
    "    ``` python\n",
    "    saver.save(session, path)\n",
    "    saver.restore(session,path)\n",
    "    ```\n",
    "    \n",
    "- Graph must be created before restoring the session. To restore graph also from the checkpoint file use following code which will restore graph as default graph\n",
    "``` python\n",
    "    meta_importer = tf.train.import_meta_graph(checkpoint_path+\".meta\")\n",
    "    \n",
    "    # Then restore session\n",
    "    sess = tf.Session()\n",
    "    meta_importer.restore(sess, checkpoint_path)\n",
    "```\n",
    "\n",
    "- When restoring graph from meta file our tensor and operation variables are not assigned automatically. So we need to find them in graph by name or other way and assign it to variables to easily use them. Some functions are\n",
    "  - ```graph.get_tensor_by_name(\"x:0\")``` here 0 indicates 1st output of operation x\n",
    "  - ```graph.get_operation_by_name(\"is_training\")```\n",
    "  - ```graph.collections``` is list of collection names\n",
    "  - ```tf.get_collection(collection_name)``` will give all variables in a collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MINST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/devbhadurkhadka/.pyenv/versions/anaconda3-5.2.0/envs/scikit_practice/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(-1, 28*28)\n",
    "x_test = x_test.reshape(-1, 28*28)\n",
    "\n",
    "train_indxes_0to4 = y_train<5\n",
    "train_x_0to4 = x_train[train_indxes_0to4]\n",
    "train_y_0to4 = y_train[train_indxes_0to4]\n",
    "\n",
    "test_indxes_0to4 = y_test<5\n",
    "test_x_0to4 = x_test[test_indxes_0to4]\n",
    "test_y_0to4 = y_test[test_indxes_0to4]\n",
    "\n",
    "\n",
    "\n",
    "(train_x_0to4, val_x_0to4, train_y_0to4, val_y_0to4) = \\\n",
    "    train_test_split(train_x_0to4, train_y_0to4, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import variance_scaling_initializer as he_initializer\n",
    "from tensorflow.nn import sparse_softmax_cross_entropy_with_logits as softmax_xentropy\n",
    "from tensorflow.layers import dense\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_leaky_relu(alpha):\n",
    "    return lambda z, name=None: tf.maximum(alpha*z,z, name=name)\n",
    "    \n",
    "\n",
    "def get_connected_layers(x, n_hidden_layers, n_neurons, n_ouputs, activation=tf.nn.elu,\n",
    "                                   batch_norm_momentum=None, dropout_rate=None, is_training=None):\n",
    "    \n",
    "\n",
    "    initializer = he_initializer()\n",
    "    \n",
    "    with tf.name_scope(\"DNN\"):\n",
    "        inputs = x\n",
    "        for l in range(n_hidden_layers):\n",
    "            if dropout_rate is not None:\n",
    "                ## this function will set inputs to zero with dropout rate probability\n",
    "                ## and divides remaining inputs with dropout rate\n",
    "                inputs = tf.layers.dropout(inputs, dropout_rate, training=is_training, \n",
    "                                  name=(\"dropout%d\"%l))\n",
    "                \n",
    "            inputs = tf.layers.dense(inputs, n_neurons, kernel_initializer=initializer,\n",
    "                           name=\"hidden%d\"%(l+1), activation=activation)\n",
    "            \n",
    "            if batch_norm_momentum is not None:\n",
    "                inputs = tf.layers.batch_normalization(inputs, momentum=batch_norm_momentum,\n",
    "                                training=is_training)\n",
    "            \n",
    "            inputs = activation(inputs, name=\"hiden%d_out\"%(l+1))\n",
    "            \n",
    "        output = tf.layers.dense(inputs, n_ouputs, name=\"output\")\n",
    "        \n",
    "    return output\n",
    "        \n",
    "\n",
    "\n",
    "def get_softmax_xentropy_loss(logits,y):\n",
    "    with tf.name_scope(\"loss\"):\n",
    "        xentropy = softmax_xentropy(labels=y, logits=logits)\n",
    "        return tf.reduce_mean(xentropy, name=\"mean_loss\")\n",
    "\n",
    "def get_optimizer_op(optimizer, loss, learning_rate=0.01):\n",
    "    with tf.name_scope(\"train\"):\n",
    "        optimizer =  optimizer(learning_rate=learning_rate)\n",
    "        optimizer_op = optimizer.minimize(loss, name=\"optimizer_op\")\n",
    "    return optimizer_op\n",
    "\n",
    "def get_validation_score(logits,y):\n",
    "    with tf.name_scope(\"validation\"):\n",
    "        preds = tf.nn.in_top_k(logits,y,1)\n",
    "        return tf.reduce_mean(tf.cast(preds, dtype=np.float32), name=\"validation_score\")\n",
    "    \n",
    "def get_batch(x,y,batch_size):\n",
    "    n_batches = len(y)//batch_size + 1\n",
    "    for i in range(n_batches):\n",
    "        indxes = np.random.choice(len(y), size=batch_size, replace=False)\n",
    "        yield x[indxes], y[indxes]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Classifier Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imp import reload\n",
    "# import my_libs\n",
    "# reload(my_libs.tf_graph_saver)\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from my_libs.tf_graph_saver import ScalerGraphSaver2\n",
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "\n",
    "\n",
    "class DNN_Classifier(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_hidden_layers=None, n_neurons=None, n_outputs=None, \n",
    "                 activation=tf.nn.elu, optimizer=tf.train.AdamOptimizer,  learning_rate=0.01, \n",
    "                 batch_norm_momentum=None, batch_size=50, dropout_rate=None):\n",
    "        self.n_hidden_layers = n_hidden_layers\n",
    "        self.n_neurons = n_neurons\n",
    "        self.learning_rate = learning_rate\n",
    "        self.activation = activation\n",
    "        self.optimizer = optimizer\n",
    "        self.batch_norm_momentum = batch_norm_momentum\n",
    "        self.batch_size = batch_size\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.n_outputs = n_outputs\n",
    "        self._session = None\n",
    "        \n",
    "        \n",
    "    def _create_graph(self):                      \n",
    "        \n",
    "        tf.reset_default_graph()\n",
    "        self._graph = tf.Graph()\n",
    "        with self._graph.as_default():\n",
    "        \n",
    "            self._x = tf.placeholder(shape=(None, 28*28), dtype=np.float32,name=\"x\")\n",
    "            self._y = tf.placeholder(shape=(None), dtype=np.int32,name=\"y\")\n",
    "\n",
    "            self._is_training = tf.placeholder_with_default(False,shape=(), name=\"is_training\")\n",
    "\n",
    "\n",
    "            self._dnn = get_connected_layers(self._x, self.n_hidden_layers, self.n_neurons, \n",
    "                                       self.n_outputs, activation=self.activation, \n",
    "                                       batch_norm_momentum=self.batch_norm_momentum, \n",
    "                                       dropout_rate=self.dropout_rate, is_training=self._is_training)\n",
    "            self._loss = get_softmax_xentropy_loss(self._dnn, self._y)\n",
    "            self._optimizer_op = get_optimizer_op(self.optimizer, self._loss, \n",
    "                                                  self.learning_rate)\n",
    "            self._validation_score = get_validation_score(self._dnn, self._y)\n",
    "\n",
    "            self._y_proba = tf.nn.softmax(self._dnn, name=\"y_proba\")\n",
    "\n",
    "            self._batch_norm_update_ops = self._graph.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "            self._saver = tf.train.Saver()\n",
    "            self._init = tf.global_variables_initializer()\n",
    "            \n",
    "        \n",
    "    def _save_params(self):\n",
    "        with self._graph.as_default():\n",
    "            global_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "            \n",
    "        vars_n_values = {global_var.op.name:value for global_var, value in \\\n",
    "                 zip(global_vars,self._session.run(global_vars))}\n",
    "        self._saved_params =  vars_n_values\n",
    "        \n",
    "    \n",
    "    def _restore_params(self):\n",
    "        var_names = list(self._saved_params.keys())\n",
    "        \n",
    "        ## get assign operations for all variables\n",
    "        assign_ops = {var_name:self._graph.get_operation_by_name(\"%s/Assign\"%var_name) \n",
    "                      for var_name in var_names}\n",
    "        ## get initialization values of all variables\n",
    "        init_values = {var_name: assign_op.inputs[1]  for var_name, assign_op \n",
    "                       in assign_ops.items()}\n",
    "        \n",
    "        ## get feed_dict for all values\n",
    "        feed_dict = {init_values[var_name]:self._saved_params[var_name] \n",
    "                     for var_name in var_names}\n",
    "        \n",
    "        \n",
    "        self._session.run(assign_ops, feed_dict=feed_dict)\n",
    "        \n",
    "    \n",
    "    def fit(self,x,y,x_val,y_val):\n",
    "        n_epoches = 500\n",
    "        max_epoches_wo_progress = 30\n",
    "        \n",
    "        self._create_graph()\n",
    "        \n",
    "        best_score=np.float(\"inf\")\n",
    "        best_epoch=0\n",
    "        if self._session: self._session.close()\n",
    "        with tf.Session(graph=self._graph).as_default() as sess:\n",
    "            self._session = sess\n",
    "            sess.run(self._init)\n",
    "            \n",
    "            graph_saver = ScalerGraphSaver2(\"DNN_GridSearch\")\n",
    "            loss_summary = graph_saver.get_summary_op(\"loss\", self._loss)\n",
    "            score_summary = graph_saver.get_summary_op(\"accuracy_score\", self._validation_score)\n",
    "            \n",
    "            with graph_saver:\n",
    "        \n",
    "                for epoch in range(n_epoches):\n",
    "                    for batch_x, batch_y in get_batch(x,y,self.batch_size):\n",
    "                        ops = [self._loss, loss_summary, self._optimizer_op]\n",
    "                        if self._batch_norm_update_ops is not None:\n",
    "                            ops.append(self._batch_norm_update_ops)\n",
    "\n",
    "                        results = sess.run(ops , feed_dict={self._x:batch_x, self._y:batch_y, \n",
    "                                               self._is_training:True})\n",
    "                        loss = results[0]\n",
    "                        loss_summary_text = results[1]\n",
    "\n",
    "\n",
    "\n",
    "                    score, score_summary_text = sess.run([self._validation_score, score_summary], \n",
    "                                     feed_dict={self._x:x_val, self._y:y_val})\n",
    "                    graph_saver.log_summary(loss_summary_text, epoch)\n",
    "                    graph_saver.log_summary(score_summary_text, epoch)\n",
    "                    \n",
    "                   \n",
    "                    \n",
    "                    if epoch%20 == 0:\n",
    "                        print(\"epoch %d, score %f, loss %f\"%(epoch, score, loss))\n",
    "                    \n",
    "                    score=loss\n",
    "                    if score < best_score:\n",
    "                        best_score = score\n",
    "                        best_epoch = epoch\n",
    "                        self._save_params()\n",
    "                    elif (epoch - best_epoch)>max_epoches_wo_progress:\n",
    "                        print(\"No progress for %d epoches.\"%max_epoches_wo_progress)\n",
    "                        break\n",
    "                \n",
    "            self._restore_params()\n",
    "            print(\"Reverting back to epoch %d \\\n",
    "                    with %f score\" %(best_epoch, best_score))\n",
    "            self._score = best_score \n",
    "            return self\n",
    "            \n",
    "                    \n",
    "    \n",
    "    def predict_proba(self,x):\n",
    "        if self._session is None:\n",
    "            raise NotFittedError(\"%s is not fitted yet\" \\\n",
    "                                                    %self.__class__.__name__)\n",
    "        \n",
    "        return self._session.run(self._y_proba, feed_dict={self._x:x, \n",
    "                                                           self._is_training:False})\n",
    "            \n",
    "    \n",
    "    def predict(self,x):\n",
    "        return np.argmax(self.predict_proba(x), axis=1)\n",
    "    \n",
    "    def score(self, x_val=None, y_val=None):\n",
    "        \n",
    "        score=self._session.run(self._validation_score, \n",
    "                             feed_dict={self._x:x_val, self._y:y_val})\n",
    "        print(\"validation score: %f\", score)\n",
    "        return score\n",
    "    \n",
    "    def _get_save_path(self, name):\n",
    "        return \"tf_checkpoints/%s\"%name\n",
    "    \n",
    "    def save(self,name):\n",
    "        self._saver.save(self._session, self._get_save_path(name))\n",
    "    \n",
    "    def restore(self, name):\n",
    "        imported_meta = tf.train.import_meta_graph(\"%s.meta\"%self._get_save_path(name))\n",
    "        graph = tf.get_default_graph()\n",
    "        self._x = graph.get_tensor_by_name(\"x:0\")\n",
    "        self._y = graph.get_tensor_by_name(\"y:0\")\n",
    "        self._loss = graph.get_operation_by_name(\"mean_loss\")\n",
    "        \n",
    "        self._validation_score = graph.get_tensor_by_name(\"validation/validation_score:0\")\n",
    "        self._y_proba = graph.get_tensor_by_name(\"y_proba:0\")\n",
    "        self._is_training = graph.get_tensor_by_name(\"is_training:0\")\n",
    "        self._session = tf.Session(graph=graph)\n",
    "        imported_meta.restore(self._session, self._get_save_path(name))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, score 0.927778, loss 0.590107\n",
      "epoch 50, score 0.958170, loss 0.096847\n",
      "epoch 100, score 0.979085, loss 0.025066\n",
      "epoch 150, score 0.977124, loss 0.000035\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 67                     with 0.982026 score\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNN_Classifier(activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c39591048>,\n",
       "        batch_norm_momentum=None, batch_size=50, dropout_rate=None,\n",
       "        learning_rate=0.01, n_hidden_layers=2, n_neurons=20, n_outputs=5,\n",
       "        optimizer=<class 'tensorflow.python.training.adam.AdamOptimizer'>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = DNN_Classifier(2, 20, 5, activation=get_leaky_relu(0.01))\n",
    "classifier.fit(train_x_0to4, train_y_0to4, val_x_0to4, val_y_0to4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save(\"Mnist-0to4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9820976843743919"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clas_re = DNN_Classifier()\n",
    "graph = clas_re.restore(\"Mnist-0to4\")\n",
    "preds = clas_re.predict(test_x_0to4)\n",
    "accuracy_score(preds, test_y_0to4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Rate With and Without Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, score 0.978431, loss 0.035092\n",
      "epoch 50, score 0.987582, loss 0.001325\n",
      "epoch 100, score 0.989542, loss 0.000238\n",
      "epoch 150, score 0.986274, loss 0.000030\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 88                     with 0.991830 score\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNN_Classifier(activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c395919d8>,\n",
       "        batch_norm_momentum=0.98, batch_size=50, dropout_rate=None,\n",
       "        learning_rate=0.01, n_hidden_layers=2, n_neurons=20, n_outputs=5,\n",
       "        optimizer=<class 'tensorflow.python.training.adam.AdamOptimizer'>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = DNN_Classifier(2, 20, 5, activation=get_leaky_relu(0.01), batch_norm_momentum=.98)\n",
    "classifier.fit(train_x_0to4, train_y_0to4, val_x_0to4, val_y_0to4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Best Parameters Using RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-23 17:38:25.754383\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "[CV] n_outputs=5, n_neurons=100, n_hidden_layers=5, batch_size=50, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c360bb268> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/devbhadurkhadka/.pyenv/versions/anaconda3-5.2.0/envs/scikit_practice/lib/python3.6/site-packages/sklearn/model_selection/_search.py:584: DeprecationWarning: \"fit_params\" as a constructor argument was deprecated in version 0.19 and will be removed in version 0.21. Pass fit parameters to the \"fit\" method instead.\n",
      "  '\"fit\" method instead.', DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, score 0.950327\n",
      "epoch 50, score 0.861765\n",
      "epoch 100, score 0.895425\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 8                     with 0.981699 score\n",
      "validation score: %f 0.9753786\n",
      "validation score: %f 0.98343956\n",
      "[CV]  n_outputs=5, n_neurons=100, n_hidden_layers=5, batch_size=50, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c360bb268>, score=0.9753785729408264, total= 3.3min\n",
      "[CV] n_outputs=5, n_neurons=100, n_hidden_layers=5, batch_size=50, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c360bb268> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, score 0.965686\n",
      "epoch 50, score 0.953922\n",
      "epoch 100, score 0.385948\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 5                     with 0.980065 score\n",
      "validation score: %f 0.9723281\n",
      "validation score: %f 0.97804654\n",
      "[CV]  n_outputs=5, n_neurons=100, n_hidden_layers=5, batch_size=50, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c360bb268>, score=0.9723281264305115, total= 3.0min\n",
      "[CV] n_outputs=5, n_neurons=100, n_hidden_layers=5, batch_size=50, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c360bb268> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  6.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, score 0.942810\n",
      "epoch 50, score 0.594771\n",
      "epoch 100, score 0.931046\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 7                     with 0.980719 score\n",
      "validation score: %f 0.97494006\n",
      "validation score: %f 0.9826234\n",
      "[CV]  n_outputs=5, n_neurons=100, n_hidden_layers=5, batch_size=50, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c360bb268>, score=0.9749400615692139, total= 3.4min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=100, activation=<function relu at 0x1a20a79950> \n",
      "epoch 0, score 0.966340\n",
      "epoch 50, score 0.223529\n",
      "epoch 100, score 0.223529\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 26                     with 0.983660 score\n",
      "validation score: %f 0.98213315\n",
      "validation score: %f 0.9954241\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=100, activation=<function relu at 0x1a20a79950>, score=0.982133150100708, total= 2.1min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=100, activation=<function relu at 0x1a20a79950> \n",
      "epoch 0, score 0.963726\n",
      "epoch 50, score 0.223529\n",
      "epoch 100, score 0.223529\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 17                     with 0.984314 score\n",
      "validation score: %f 0.98147947\n",
      "validation score: %f 0.9931906\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=100, activation=<function relu at 0x1a20a79950>, score=0.9814794659614563, total= 1.8min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=100, activation=<function relu at 0x1a20a79950> \n",
      "epoch 0, score 0.950654\n",
      "epoch 50, score 0.223529\n",
      "epoch 100, score 0.223529\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 15                     with 0.983660 score\n",
      "validation score: %f 0.9784267\n",
      "validation score: %f 0.99128443\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=100, activation=<function relu at 0x1a20a79950>, score=0.9784266948699951, total= 1.8min\n",
      "[CV] n_outputs=5, n_neurons=80, n_hidden_layers=5, batch_size=50, activation=<function elu at 0x1a20af31e0> \n",
      "epoch 0, score 0.954575\n",
      "epoch 50, score 0.223529\n",
      "epoch 100, score 0.200327\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 7                     with 0.979085 score\n",
      "validation score: %f 0.97254604\n",
      "validation score: %f 0.98284036\n",
      "[CV]  n_outputs=5, n_neurons=80, n_hidden_layers=5, batch_size=50, activation=<function elu at 0x1a20af31e0>, score=0.9725460410118103, total= 2.1min\n",
      "[CV] n_outputs=5, n_neurons=80, n_hidden_layers=5, batch_size=50, activation=<function elu at 0x1a20af31e0> \n",
      "epoch 0, score 0.948693\n",
      "epoch 50, score 0.223529\n",
      "epoch 100, score 0.223529\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 2                     with 0.978431 score\n",
      "validation score: %f 0.97385335\n",
      "validation score: %f 0.9807703\n",
      "[CV]  n_outputs=5, n_neurons=80, n_hidden_layers=5, batch_size=50, activation=<function elu at 0x1a20af31e0>, score=0.973853349685669, total= 2.0min\n",
      "[CV] n_outputs=5, n_neurons=80, n_hidden_layers=5, batch_size=50, activation=<function elu at 0x1a20af31e0> \n",
      "epoch 0, score 0.957190\n",
      "epoch 50, score 0.191830\n",
      "epoch 100, score 0.191830\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 8                     with 0.980065 score\n",
      "validation score: %f 0.97602963\n",
      "validation score: %f 0.98507464\n",
      "[CV]  n_outputs=5, n_neurons=80, n_hidden_layers=5, batch_size=50, activation=<function elu at 0x1a20af31e0>, score=0.976029634475708, total= 2.4min\n",
      "[CV] n_outputs=5, n_neurons=80, n_hidden_layers=5, batch_size=50, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c360bb268> \n",
      "epoch 0, score 0.960458\n",
      "epoch 50, score 0.701961\n",
      "epoch 100, score 0.713072\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 6                     with 0.978431 score\n",
      "validation score: %f 0.9716745\n",
      "validation score: %f 0.9813695\n",
      "[CV]  n_outputs=5, n_neurons=80, n_hidden_layers=5, batch_size=50, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c360bb268>, score=0.9716745018959045, total= 2.6min\n",
      "[CV] n_outputs=5, n_neurons=80, n_hidden_layers=5, batch_size=50, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c360bb268> \n",
      "epoch 0, score 0.965359\n",
      "epoch 50, score 0.845425\n",
      "epoch 100, score 0.499346\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 5                     with 0.980065 score\n",
      "validation score: %f 0.9771217\n",
      "validation score: %f 0.98322165\n",
      "[CV]  n_outputs=5, n_neurons=80, n_hidden_layers=5, batch_size=50, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c360bb268>, score=0.9771217107772827, total= 2.6min\n",
      "[CV] n_outputs=5, n_neurons=80, n_hidden_layers=5, batch_size=50, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c360bb268> \n",
      "epoch 0, score 0.957190\n",
      "epoch 50, score 0.913072\n",
      "epoch 100, score 0.944118\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 7                     with 0.980719 score\n",
      "validation score: %f 0.975158\n",
      "validation score: %f 0.98344046\n",
      "[CV]  n_outputs=5, n_neurons=80, n_hidden_layers=5, batch_size=50, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c360bb268>, score=0.9751579761505127, total= 2.4min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=50, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c360bb268> \n",
      "epoch 0, score 0.955882\n",
      "epoch 50, score 0.470915\n",
      "epoch 100, score 0.877451\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 8                     with 0.977451 score\n",
      "validation score: %f 0.9741802\n",
      "validation score: %f 0.9832761\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=50, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c360bb268>, score=0.9741802215576172, total= 3.4min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=50, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c360bb268> \n",
      "epoch 0, score 0.956209\n",
      "epoch 50, score 0.887909\n",
      "epoch 100, score 0.813399\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 13                     with 0.984641 score\n",
      "validation score: %f 0.9806079\n",
      "validation score: %f 0.98747075\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=50, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c360bb268>, score=0.9806079268455505, total= 3.4min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=50, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c360bb268> \n",
      "epoch 0, score 0.966667\n",
      "epoch 50, score 0.472222\n",
      "epoch 100, score 0.436928\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 8                     with 0.977778 score\n",
      "validation score: %f 0.9711266\n",
      "validation score: %f 0.98017216\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, batch_size=50, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c360bb268>, score=0.9711266160011292, total= 3.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed: 39.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, score 0.962092\n",
      "epoch 50, score 0.223529\n",
      "epoch 100, score 0.223529\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 15                     with 0.983987 score\n",
      "2019-08-23 18:21:32.915014\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from datetime import datetime\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "\n",
    "print(datetime.today())\n",
    "params_dist = {\n",
    "    \"n_neurons\":[80,100, 120],\n",
    "    \"n_hidden_layers\": [5],\n",
    "    \"n_outputs\": [5],\n",
    "    \"activation\": [tf.nn.relu, get_leaky_relu(0.01), tf.nn.elu],\n",
    "    \"batch_size\": [50,100]\n",
    "}\n",
    "\n",
    "classifier = DNN_Classifier()\n",
    "fit_params = {\"x_val\": val_x_0to4, \"y_val\": val_y_0to4}\n",
    "rand_search = RandomizedSearchCV(classifier, params_dist, n_iter=5, cv=3,\n",
    "                                 n_jobs=1, fit_params=fit_params, verbose=3)\n",
    "rand_search.fit(train_x_0to4, train_y_0to4)\n",
    "\n",
    "print(datetime.today())\n",
    "\n",
    "rand_search.best_estimator_.save(\"Mnist-0to4-best1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_outputs': 5,\n",
       " 'n_neurons': 120,\n",
       " 'n_hidden_layers': 5,\n",
       " 'batch_size': 100,\n",
       " 'activation': <function tensorflow.python.ops.gen_nn_ops.relu(features, name=None)>}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-27 18:13:28.455102\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "[CV] n_outputs=5, n_neurons=150, n_hidden_layers=5, batch_size=80, batch_norm_momentum=0.98, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1a2a5ea9d8> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/devbhadurkhadka/.pyenv/versions/anaconda3-5.2.0/envs/scikit_practice/lib/python3.6/site-packages/sklearn/model_selection/_search.py:584: DeprecationWarning: \"fit_params\" as a constructor argument was deprecated in version 0.19 and will be removed in version 0.21. Pass fit parameters to the \"fit\" method instead.\n",
      "  '\"fit\" method instead.', DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, score 0.973203, loss 0.030403\n",
      "epoch 50, score 0.985294, loss 0.002224\n",
      "epoch 100, score 0.989216, loss 0.003985\n",
      "epoch 150, score 0.993137, loss 0.000000\n",
      "epoch 200, score 0.990850, loss 0.000000\n",
      "epoch 250, score 0.989869, loss 0.000027\n",
      "epoch 300, score 0.990196, loss 0.048437\n",
      "epoch 350, score 0.991830, loss 0.000000\n",
      "epoch 400, score 0.993791, loss 0.000000\n",
      "epoch 450, score 0.990196, loss 0.000001\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 383                     with 0.000000 score\n",
      "validation score: %f 0.9919381\n",
      "validation score: %f 1.0\n",
      "[CV]  n_outputs=5, n_neurons=150, n_hidden_layers=5, batch_size=80, batch_norm_momentum=0.98, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1a2a5ea9d8>, score=0.9919381141662598, total=18.9min\n",
      "[CV] n_outputs=5, n_neurons=150, n_hidden_layers=5, batch_size=80, batch_norm_momentum=0.98, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1a2a5ea9d8> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 18.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, score 0.972549, loss 0.063548\n",
      "epoch 50, score 0.991176, loss 0.000083\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-db8b46b61e3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m rand_search = RandomizedSearchCV(classifier, params_dist, n_iter=5, cv=3,\n\u001b[1;32m     18\u001b[0m                                  n_jobs=1, fit_params=fit_params, verbose=3)\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mrand_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x_0to4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y_0to4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoday\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.2.0/envs/scikit_practice/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.2.0/envs/scikit_practice/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.2.0/envs/scikit_practice/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.2.0/envs/scikit_practice/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.2.0/envs/scikit_practice/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.2.0/envs/scikit_practice/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.2.0/envs/scikit_practice/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.2.0/envs/scikit_practice/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.2.0/envs/scikit_practice/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-634279ac8f18>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, x_val, y_val)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                         results = sess.run(ops , feed_dict={self._x:batch_x, self._y:batch_y, \n\u001b[0;32m--> 107\u001b[0;31m                                                self._is_training:True})\n\u001b[0m\u001b[1;32m    108\u001b[0m                         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                         \u001b[0mloss_summary_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.2.0/envs/scikit_practice/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.2.0/envs/scikit_practice/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.2.0/envs/scikit_practice/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.2.0/envs/scikit_practice/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.2.0/envs/scikit_practice/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.2.0/envs/scikit_practice/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "print(datetime.today())\n",
    "params_dist = {\n",
    "    \"n_neurons\":[120,150],\n",
    "    \"n_hidden_layers\": [5],\n",
    "    \"n_outputs\": [5],\n",
    "    \"batch_norm_momentum\": [.98, .99],\n",
    "    \"activation\": [tf.nn.relu, get_leaky_relu(0.01), tf.nn.elu],\n",
    "    \"batch_size\": [80,100]\n",
    "}\n",
    "\n",
    "classifier = DNN_Classifier()\n",
    "fit_params = {\"x_val\": val_x_0to4, \"y_val\": val_y_0to4}\n",
    "rand_search = RandomizedSearchCV(classifier, params_dist, n_iter=5, cv=3,\n",
    "                                 n_jobs=1, fit_params=fit_params, verbose=3)\n",
    "rand_search.fit(train_x_0to4, train_y_0to4)\n",
    "\n",
    "print(datetime.today())\n",
    "\n",
    "rand_search.best_estimator_.save(\"Mnist-0to4-best_batch_norm\")\n",
    "\n",
    "preds = rand_search.best_estimator_.predict(test_x_0to4)\n",
    "\"test accuracy: %f\"%accuracy_score(preds, test_y_0to4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test accuracy: 0.995524'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\"test accuracy: %f\"%accuracy_score(preds, test_y_0to4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_outputs': 5,\n",
       " 'n_neurons': 120,\n",
       " 'n_hidden_layers': 5,\n",
       " 'batch_size': 100,\n",
       " 'batch_norm_momentum': 0.98,\n",
       " 'activation': <function __main__.get_leaky_relu.<locals>.<lambda>(z, name=None)>}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-23 21:00:30.181454\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.6, batch_size=50, activation=<function elu at 0x1a20af31e0> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/devbhadurkhadka/.pyenv/versions/anaconda3-5.2.0/envs/scikit_practice/lib/python3.6/site-packages/sklearn/model_selection/_search.py:584: DeprecationWarning: \"fit_params\" as a constructor argument was deprecated in version 0.19 and will be removed in version 0.21. Pass fit parameters to the \"fit\" method instead.\n",
      "  '\"fit\" method instead.', DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, score 0.200654, loss 2.511327\n",
      "epoch 50, score 0.191503, loss 1.673325\n",
      "epoch 100, score 0.223529, loss 1.784896\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 10                     with 0.370261 score\n",
      "validation score: %f 0.363983\n",
      "validation score: %f 0.37920138\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.6, batch_size=50, activation=<function elu at 0x1a20af31e0>, score=0.36398300528526306, total= 3.2min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.6, batch_size=50, activation=<function elu at 0x1a20af31e0> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, score 0.191503, loss 1.979267\n",
      "epoch 50, score 0.191503, loss 1.710331\n",
      "epoch 100, score 0.191830, loss 1.617060\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 6                     with 0.223529 score\n",
      "validation score: %f 0.22083016\n",
      "validation score: %f 0.21958926\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.6, batch_size=50, activation=<function elu at 0x1a20af31e0>, score=0.22083015739917755, total= 3.6min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.6, batch_size=50, activation=<function elu at 0x1a20af31e0> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  6.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, score 0.200327, loss 1.459546\n",
      "epoch 50, score 0.200327, loss 1.686456\n",
      "epoch 100, score 0.192810, loss 1.711437\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 5                     with 0.223529 score\n",
      "validation score: %f 0.22368708\n",
      "validation score: %f 0.21816102\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.6, batch_size=50, activation=<function elu at 0x1a20af31e0>, score=0.223687082529068, total= 3.3min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.2, batch_size=100, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c3852d7b8> \n",
      "epoch 0, score 0.933333, loss 0.397353\n",
      "epoch 50, score 0.951307, loss 0.435087\n",
      "epoch 100, score 0.928105, loss 0.497548\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 6                     with 0.972549 score\n",
      "validation score: %f 0.9633947\n",
      "validation score: %f 0.97042\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.2, batch_size=100, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c3852d7b8>, score=0.9633947014808655, total= 2.8min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.2, batch_size=100, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c3852d7b8> \n",
      "epoch 0, score 0.921569, loss 0.541837\n",
      "epoch 50, score 0.957843, loss 0.247198\n",
      "epoch 100, score 0.954575, loss 0.401142\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 13                     with 0.980719 score\n",
      "validation score: %f 0.9778843\n",
      "validation score: %f 0.97859126\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.2, batch_size=100, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c3852d7b8>, score=0.9778842926025391, total= 2.9min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.2, batch_size=100, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c3852d7b8> \n",
      "epoch 0, score 0.933007, loss 0.471347\n",
      "epoch 50, score 0.799346, loss 0.802404\n",
      "epoch 100, score 0.875817, loss 0.431196\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 10                     with 0.981046 score\n",
      "validation score: %f 0.9761386\n",
      "validation score: %f 0.98305917\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.2, batch_size=100, activation=<function get_leaky_relu.<locals>.<lambda> at 0x1c3852d7b8>, score=0.9761385917663574, total= 2.8min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.2, batch_size=100, activation=<function elu at 0x1a20af31e0> \n",
      "epoch 0, score 0.941503, loss 0.617818\n",
      "epoch 50, score 0.200327, loss 1.626830\n",
      "epoch 100, score 0.223529, loss 1.547778\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 14                     with 0.979739 score\n",
      "validation score: %f 0.9736355\n",
      "validation score: %f 0.9811516\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.2, batch_size=100, activation=<function elu at 0x1a20af31e0>, score=0.9736354947090149, total= 3.0min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.2, batch_size=100, activation=<function elu at 0x1a20af31e0> \n",
      "epoch 0, score 0.914052, loss 0.679885\n",
      "epoch 50, score 0.405556, loss 1.093436\n",
      "epoch 100, score 0.223529, loss 1.633742\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 7                     with 0.971242 score\n",
      "validation score: %f 0.9694956\n",
      "validation score: %f 0.97254455\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.2, batch_size=100, activation=<function elu at 0x1a20af31e0>, score=0.9694955945014954, total= 2.9min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.2, batch_size=100, activation=<function elu at 0x1a20af31e0> \n",
      "epoch 0, score 0.924837, loss 0.512203\n",
      "epoch 50, score 0.193137, loss 1.523156\n",
      "epoch 100, score 0.223529, loss 1.611071\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 14                     with 0.980065 score\n",
      "validation score: %f 0.97472215\n",
      "validation score: %f 0.98153394\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.2, batch_size=100, activation=<function elu at 0x1a20af31e0>, score=0.974722146987915, total= 3.0min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.6, batch_size=80, activation=<function relu at 0x1a20a79950> \n",
      "epoch 0, score 0.200327, loss 1.817046\n",
      "epoch 50, score 0.192810, loss 1.605816\n",
      "epoch 100, score 0.223529, loss 1.612167\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 9                     with 0.384314 score\n",
      "validation score: %f 0.37814575\n",
      "validation score: %f 0.3874816\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.6, batch_size=80, activation=<function relu at 0x1a20a79950>, score=0.3781457543373108, total= 3.0min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.6, batch_size=80, activation=<function relu at 0x1a20a79950> \n",
      "epoch 0, score 0.192484, loss 1.709757\n",
      "epoch 50, score 0.191830, loss 6.695802\n",
      "epoch 100, score 0.223529, loss 1.625347\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 11                     with 0.372549 score\n",
      "validation score: %f 0.36997494\n",
      "validation score: %f 0.37250096\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.6, batch_size=80, activation=<function relu at 0x1a20a79950>, score=0.36997494101524353, total= 3.1min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.6, batch_size=80, activation=<function relu at 0x1a20a79950> \n",
      "epoch 0, score 0.223529, loss 1.655535\n",
      "epoch 50, score 0.192810, loss 1.612964\n",
      "epoch 100, score 0.223529, loss 1.590082\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 13                     with 0.335621 score\n",
      "validation score: %f 0.33002833\n",
      "validation score: %f 0.32160366\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.6, batch_size=80, activation=<function relu at 0x1a20a79950>, score=0.33002832531929016, total= 3.2min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.4, batch_size=50, activation=<function relu at 0x1a20a79950> \n",
      "epoch 0, score 0.506863, loss 1.296286\n",
      "epoch 50, score 0.223529, loss 1.611830\n",
      "epoch 100, score 0.223529, loss 1.611283\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 3                     with 0.582353 score\n",
      "validation score: %f 0.5708683\n",
      "validation score: %f 0.58789563\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.4, batch_size=50, activation=<function relu at 0x1a20a79950>, score=0.5708683133125305, total= 3.2min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.4, batch_size=50, activation=<function relu at 0x1a20a79950> \n",
      "epoch 0, score 0.540196, loss 1.373591\n",
      "epoch 50, score 0.411438, loss 1.295681\n",
      "epoch 100, score 0.389542, loss 1.559840\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 5                     with 0.593464 score\n",
      "validation score: %f 0.5815448\n",
      "validation score: %f 0.5834287\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.4, batch_size=50, activation=<function relu at 0x1a20a79950>, score=0.581544816493988, total= 3.5min\n",
      "[CV] n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.4, batch_size=50, activation=<function relu at 0x1a20a79950> \n",
      "epoch 0, score 0.529412, loss 1.236342\n",
      "epoch 50, score 0.223529, loss 1.608894\n",
      "epoch 100, score 0.223529, loss 1.610012\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 7                     with 0.599346 score\n",
      "validation score: %f 0.58683807\n",
      "validation score: %f 0.58590263\n",
      "[CV]  n_outputs=5, n_neurons=120, n_hidden_layers=5, dropout_rate=0.4, batch_size=50, activation=<function relu at 0x1a20a79950>, score=0.5868380665779114, total= 3.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed: 47.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, score 0.951961, loss 0.394898\n",
      "epoch 50, score 0.191830, loss 1.617283\n",
      "epoch 100, score 0.192810, loss 1.657724\n",
      "No progress for 100 epoches.\n",
      "Reverting back to epoch 6                     with 0.976471 score\n",
      "2019-08-23 21:52:37.437255\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9778166958552248"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(datetime.today())\n",
    "params_dist = {\n",
    "    \"n_neurons\":[120],\n",
    "    \"n_hidden_layers\": [5],\n",
    "    \"n_outputs\": [5],\n",
    "    \"dropout_rate\": [.6, .4, .2],\n",
    "    \"activation\": [tf.nn.relu, get_leaky_relu(0.01), tf.nn.elu],\n",
    "    \"batch_size\": [50,80,100]\n",
    "}\n",
    "\n",
    "classifier = DNN_Classifier()\n",
    "fit_params = {\"x_val\": val_x_0to4, \"y_val\": val_y_0to4}\n",
    "rand_search3 = RandomizedSearchCV(classifier, params_dist, n_iter=5, cv=3,\n",
    "                                 n_jobs=1, fit_params=fit_params, verbose=3)\n",
    "rand_search3.fit(train_x_0to4, train_y_0to4)\n",
    "\n",
    "print(datetime.today())\n",
    "\n",
    "rand_search3.best_estimator_.save(\"Mnist-0to4-best_dropoutdsf\")\n",
    "\n",
    "preds = rand_search3.best_estimator_.predict(test_x_0to4)\n",
    "accuracy_score(preds, test_y_0to4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_outputs': 5,\n",
       " 'n_neurons': 120,\n",
       " 'n_hidden_layers': 5,\n",
       " 'dropout_rate': 0.2,\n",
       " 'batch_size': 100,\n",
       " 'activation': <function tensorflow.python.ops.gen_nn_ops.elu(features, name=None)>}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_search3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
