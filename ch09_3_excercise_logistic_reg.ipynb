{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/devbhadurkhadka/.pyenv/versions/anaconda3-5.2.0/envs/scikit_practice/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from os import path\n",
    "from my_libs.tf_graph_saver import ScalerGraphSaver\n",
    "\n",
    "checkpoint_path = \"tf_checkpoints\"\n",
    "\n",
    "def save_checkpoint(step):\n",
    "    chk_path = \"{}/epoch.ckpt\".format(checkpoint_path)\n",
    "    sess = tf.get_default_session()\n",
    "    saver = tf.train.Saver(max_to_keep=2,)\n",
    "    saver.save(sess, chk_path)\n",
    "    \n",
    "    \n",
    "def restore_checkpoint():\n",
    "    chk_path = \"{}/epoch.ckpt\".format(checkpoint_path)\n",
    "    sess = tf.get_default_session()\n",
    "    if path.exists(chk_path+\".index\"):\n",
    "        saver = tf.train.Saver(max_to_keep=2,)\n",
    "        saver.restore(sess, chk_path)\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "    \n",
    "\n",
    "def logistic_regression_fit(features, targets):\n",
    "    '''\n",
    "    features: scaled feature including bais terms\n",
    "    targets: binary target 0 or 1\n",
    "    '''\n",
    "    n_epoches = 1000\n",
    "    lr = 0.1\n",
    "    ep = 1e-15\n",
    "    m,n = features.shape\n",
    "    X = tf.constant(features, dtype=tf.float32, name=\"X\")\n",
    "    y = tf.constant(targets, dtype=tf.float32, name=\"y\")\n",
    "    \n",
    "    theta = tf.Variable(tf.random_uniform((n,1),-1,1), dtype=tf.float32, name=\"theta\")\n",
    "    cur_epoch = tf.Variable(0, dtype=tf.int32, name=\"cur_epoch\")\n",
    "    \n",
    "    with tf.name_scope(\"loss\") as scope:\n",
    "        lin_preds = tf.matmul(X, theta)\n",
    "        preds = tf.sigmoid(lin_preds)\n",
    "        log_loss = -tf.reduce_mean(y*tf.log(preds+ep)+(1-y)*tf.log(1-preds+ep))\n",
    "#         log_loss = tf.losses.log_loss(y,preds)\n",
    "    \n",
    "    with tf.name_scope(\"train\") as scope:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=lr)\n",
    "        train = optimizer.minimize(log_loss)\n",
    "        \n",
    "    with tf.name_scope(\"init\") as scope:\n",
    "        init = tf.global_variables_initializer()\n",
    "    \n",
    "    with tf.name_scope(\"save\") as scope:\n",
    "        saver = tf.train.Saver()\n",
    "        inc_epoch = tf.assign(cur_epoch, cur_epoch+1)\n",
    "\n",
    "    with ScalerGraphSaver(\"ch09_excercise\", log_loss) as graph_saver:\n",
    "        with tf.Session() as sess:\n",
    "            if not restore_checkpoint():\n",
    "                sess.run(init)\n",
    "\n",
    "            epoch_start = cur_epoch.eval()\n",
    "            display(epoch_start)\n",
    "\n",
    "            for epoch in range(epoch_start, n_epoches):\n",
    "                sess.run(train)\n",
    "                sess.run(inc_epoch)\n",
    "                graph_saver.log_summary(epoch, None)\n",
    "                if epoch%100==0:\n",
    "                    save_checkpoint(epoch)\n",
    "                    print(\"log_loss: {}\".format(log_loss.eval()))\n",
    "                if epoch==500:\n",
    "                    raise  Exception(\"Terminated to test saver\")\n",
    "            best_theta = theta.eval()\n",
    "    \n",
    "    return best_theta\n",
    "    \n",
    "\n",
    "def logistic_regression_predict(theta,X):\n",
    "    theta_tf = tf.constant(theta, dtype=tf.float32, name=\"theta\")\n",
    "    X_tf = tf.constant(X, dtype=tf.float32, name=\"X\")\n",
    "    lin_preds = tf.matmul(X_tf, theta_tf)\n",
    "    preds = tf.sigmoid(lin_preds)\n",
    "    with tf.Session() as sess:\n",
    "        predictions = preds.eval()\n",
    "    return predictions>=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "m,n = 3000,5\n",
    "X,y = make_moons(m, shuffle=True, noise=0.2)\n",
    "# X = StandardScaler().fit_transform(X)\n",
    "X = np.c_[np.ones((m,1)), X]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_loss: 0.31353750824928284\n",
      "log_loss: 0.3081745505332947\n",
      "log_loss: 0.30435600876808167\n",
      "log_loss: 0.30157625675201416\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.23651123],\n",
       "       [ 1.2551633 ],\n",
       "       [-3.552615  ]], dtype=float32)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "theta = logistic_regression_fit(X,y.reshape(-1,1))\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8666222074024675"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       ...,\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 0]])"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "tn = -1\n",
    "preds = logistic_regression_predict(theta,X[:tn])\n",
    "display(accuracy_score(y[:tn], preds))\n",
    "np.c_[y[:tn], preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.train.Saver?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver.last_checkpoints?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
