{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "x=tf.Variable(3.0, name=\"x\", dtype=tf.float32)\n",
    "y=tf.Variable(4.0, name=\"y\", dtype=tf.float32)\n",
    "\n",
    "f = x*x*y+y+2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Above statement only defines tensorflow graph it doesn't yet initialize variables or do calculations\n",
    "- x,y and f are nodes and tensorflow graph. Which are automatically added to default graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(x.initializer)\n",
    "sess.run(y.initializer)\n",
    "result = sess.run(f)\n",
    "sess.close()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using \"with\" Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    result = f.eval()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing Global Variables At Once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    result = f.eval()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive Session\n",
    "- To do experiment with one session, need to call close after done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_sess = tf.InteractiveSession() # Crete and set session as default\n",
    "init.run()\n",
    "result = f.eval()\n",
    "in_sess.close()\n",
    "result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent Using Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bais</th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.344766</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.628559</td>\n",
       "      <td>-0.153758</td>\n",
       "      <td>-0.974429</td>\n",
       "      <td>-0.049597</td>\n",
       "      <td>1.052548</td>\n",
       "      <td>-1.327835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.332238</td>\n",
       "      <td>-0.607019</td>\n",
       "      <td>0.327041</td>\n",
       "      <td>-0.263336</td>\n",
       "      <td>0.861439</td>\n",
       "      <td>-0.092512</td>\n",
       "      <td>1.043185</td>\n",
       "      <td>-1.322844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.782699</td>\n",
       "      <td>1.856182</td>\n",
       "      <td>1.155620</td>\n",
       "      <td>-0.049016</td>\n",
       "      <td>-0.820777</td>\n",
       "      <td>-0.025843</td>\n",
       "      <td>1.038503</td>\n",
       "      <td>-1.332827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.932968</td>\n",
       "      <td>1.856182</td>\n",
       "      <td>0.156966</td>\n",
       "      <td>-0.049833</td>\n",
       "      <td>-0.766028</td>\n",
       "      <td>-0.050329</td>\n",
       "      <td>1.038503</td>\n",
       "      <td>-1.337818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.012881</td>\n",
       "      <td>1.856182</td>\n",
       "      <td>0.344711</td>\n",
       "      <td>-0.032906</td>\n",
       "      <td>-0.759847</td>\n",
       "      <td>-0.085616</td>\n",
       "      <td>1.038503</td>\n",
       "      <td>-1.337818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bais    MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  \\\n",
       "0   1.0  2.344766  0.982143  0.628559  -0.153758   -0.974429 -0.049597   \n",
       "1   1.0  2.332238 -0.607019  0.327041  -0.263336    0.861439 -0.092512   \n",
       "2   1.0  1.782699  1.856182  1.155620  -0.049016   -0.820777 -0.025843   \n",
       "3   1.0  0.932968  1.856182  0.156966  -0.049833   -0.766028 -0.050329   \n",
       "4   1.0 -0.012881  1.856182  0.344711  -0.032906   -0.759847 -0.085616   \n",
       "\n",
       "   Latitude  Longitude  \n",
       "0  1.052548  -1.327835  \n",
       "1  1.043185  -1.322844  \n",
       "2  1.038503  -1.332827  \n",
       "3  1.038503  -1.337818  \n",
       "4  1.038503  -1.337818  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "housing_data = fetch_california_housing()\n",
    "m,n = housing_data.data.shape\n",
    "scaled_data = StandardScaler().fit_transform(housing_data.data)\n",
    "housing_data_df = DataFrame(scaled_data, columns=housing_data.feature_names)\n",
    "housing_data_df[\"bais\"] = np.ones(m)\n",
    "columns = [\"bais\"] + list(housing_data_df.columns[:-1])\n",
    "housing_data_df = housing_data_df[columns]\n",
    "housing_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "lr = 0.01\n",
    "\n",
    "X = tf.constant(housing_data_df.values, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing_data.target.reshape(-1,1), dtype=tf.float32, name=\"y\")\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform([n+1,1], -1.0,1.0,dtype=\n",
    "                                     tf.float32), dtype=tf.float32, name=\"theta\")\n",
    "preds_op = tf.matmul(X,theta,name=\"predictions\")\n",
    "error_op = preds_op - y\n",
    "grad_op = (2/m) * tf.matmul(tf.transpose(X), error_op, name=\"gradients\")\n",
    "training_op = tf.assign(theta, theta-lr*grad_op)\n",
    "\n",
    "mse_op = tf.reduce_mean(tf.square(error_op), name=\"mse\")\n",
    "init_op = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_gradient_descent(training_op, n_epoch=1000):\n",
    "    with tf.Session() as sess:\n",
    "        ## The line below is added to avoid error \n",
    "        ## \"FailedPreconditionError: Attempting to use uninitialized value theta_23\"\n",
    "        ## when using MomentumOptimizer\n",
    "#         tf.initialize_all_variables().run()\n",
    "        sess.run(init_op)\n",
    "        theta.eval()\n",
    "        with MSE_Graph_Saver(mse_op) as graph_saver:\n",
    "            for epoch in range(n_epoch):\n",
    "                sess.run(training_op)\n",
    "                if epoch%100==0:\n",
    "                    print(mse_op.eval())\n",
    "                graph_saver.log_summary(epoch, None)\n",
    "        best_theta = theta.eval()\n",
    "        print(best_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'__enter__'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.6266003\n",
      "0.7294788\n",
      "0.578965\n",
      "0.5592433\n",
      "0.54923034\n",
      "0.54227024\n",
      "0.53726745\n",
      "0.53366005\n",
      "0.53105795\n",
      "0.5291809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'__exit__'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.0685523 ]\n",
      " [ 0.7962932 ]\n",
      " [ 0.13590078]\n",
      " [-0.15879823]\n",
      " [ 0.19819374]\n",
      " [ 0.00216718]\n",
      " [-0.04006612]\n",
      " [-0.80615646]\n",
      " [-0.77081573]]\n"
     ]
    }
   ],
   "source": [
    "perform_gradient_descent(training_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Auto Diff\n",
    "- Auto diff calculates the gradient numerically with respect to given variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.668069\n",
      "0.7467046\n",
      "0.63447845\n",
      "0.6107754\n",
      "0.5934411\n",
      "0.5798341\n",
      "0.56907713\n",
      "0.560532\n",
      "0.55371314\n",
      "0.548249\n",
      "[[ 2.0685525 ]\n",
      " [ 0.9469755 ]\n",
      " [ 0.16062963]\n",
      " [-0.45007995]\n",
      " [ 0.44195756]\n",
      " [ 0.00920807]\n",
      " [-0.04537104]\n",
      " [-0.484403  ]\n",
      " [-0.46691895]]\n"
     ]
    }
   ],
   "source": [
    "auto_diff_grad = tf.gradients(mse_op,[theta])[0]\n",
    "auto_diff_train_op = tf.assign(theta, theta-lr*auto_diff_grad)\n",
    "\n",
    "perform_gradient_descent(auto_diff_train_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Optimizer\n",
    "- Optimizer automatically performs gradient descent on cost function operator\n",
    "- It automatically detects the variables in the cost function and change it to reduce the cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Descent Optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.648159\n",
      "0.7675881\n",
      "0.6371839\n",
      "0.60500616\n",
      "0.5829837\n",
      "0.5670564\n",
      "0.55549943\n",
      "0.5471045\n",
      "0.5409999\n",
      "0.5365559\n",
      "[[ 2.0685525 ]\n",
      " [ 0.8178526 ]\n",
      " [ 0.15121251]\n",
      " [-0.17845586]\n",
      " [ 0.2051815 ]\n",
      " [ 0.00745886]\n",
      " [-0.04182141]\n",
      " [-0.67430985]\n",
      " [-0.64045894]]\n"
     ]
    }
   ],
   "source": [
    "tf.train.GradientDescentOptimizer(learning_rate=lr)\n",
    "gd_optimiser_train_op = optimizer.minimize(mse_op)\n",
    "perform_gradient_descent(gd_optimiser_train_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Momentum Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8320448\n",
      "0.5571656\n",
      "0.5362444\n",
      "0.5290273\n",
      "0.5263092\n",
      "0.52520233\n",
      "0.5247241\n",
      "0.5245088\n",
      "0.5244095\n",
      "0.5243629\n",
      "[[ 2.0685587 ]\n",
      " [ 0.83449966]\n",
      " [ 0.11978285]\n",
      " [-0.27453005]\n",
      " [ 0.3130455 ]\n",
      " [-0.00419122]\n",
      " [-0.03951756]\n",
      " [-0.8877857 ]\n",
      " [-0.8589985 ]]\n"
     ]
    }
   ],
   "source": [
    "m_optimizer = tf.train.MomentumOptimizer(learning_rate=lr, momentum=0.75)\n",
    "momentum_optimizer_train_op = m_optimizer.minimize(mse_op)\n",
    "perform_gradient_descent(momentum_optimizer_train_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minibatch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fetch_minibatch(batch_size):\n",
    "    n_batches =  m//batch_size\n",
    "    rand_index = np.random.permutation(m)\n",
    "    X = housing_data_df.values\n",
    "    for batch in range(n_batches):\n",
    "        cur_index = rand_index[batch*batch_size:(batch+1)*batch_size]\n",
    "        y = housing_data.target.reshape(-1,1)[cur_index, :]\n",
    "        yield (X[cur_index,:], y)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def perform_minibatch_gd(n_epoch=500):\n",
    "    lr=0.001\n",
    "    batch_size=1000\n",
    "    ## placeholder is used to send parameters when running the operations\n",
    "    X_mini = tf.placeholder(dtype=tf.float32, shape=(None,  n+1), name=\"X\")\n",
    "    y_mini = tf.placeholder(dtype=tf.float32, shape=(None,  1), name=\"y\")\n",
    "\n",
    "    theta = tf.Variable(tf.random_uniform([n+1,1], -1.0,1.0,dtype=\n",
    "                                         tf.float32), dtype=tf.float32, name=\"theta\")\n",
    "    with tf.name_scope(\"gradient\") as scope:\n",
    "        preds_op = tf.matmul(X_mini,theta,name=\"predict\")\n",
    "        error_op = preds_op - y_mini\n",
    "        grad_op = (2/batch_size) * tf.matmul(tf.transpose(X_mini), \n",
    "                                             error_op, name=\"find_gradient\")\n",
    "    \n",
    "    with tf.name_scope(\"step\") as scope:\n",
    "        training_op = tf.assign(theta, theta-lr*grad_op)\n",
    "    \n",
    "    with tf.name_scope(\"loss\") as scope:\n",
    "        mse_mini = tf.reduce_mean(tf.square(error_op))\n",
    "    \n",
    "    \n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        init_op = tf.global_variables_initializer()\n",
    "        sess.run(init_op)\n",
    "        \n",
    "        with MSE_Graph_Saver(mse_mini) as graph_saver:\n",
    "            for epoch in range(n_epoch):\n",
    "                for x,y in fetch_minibatch(batch_size):\n",
    "                    feed_dict={X_mini:x, y_mini:y}\n",
    "                    sess.run(training_op, feed_dict=feed_dict)\n",
    "                    \n",
    "                \n",
    "                mse_str = graph_saver.log_summary(epoch, feed_dict)\n",
    "                    \n",
    "            best_theta = theta.eval()\n",
    "    \n",
    "    return best_theta\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Graph Summary\n",
    "- Following class logs graph summary in a directory which can be viewed using tensorboard command\n",
    "\n",
    "```\n",
    "tensorboard --logdir <dir path>\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "class MSE_Graph_Saver():\n",
    "    def __init__(self, mse):\n",
    "        root_dir = \"tf_logs\"\n",
    "        now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "        self.log_dir = \"{}/run_{}/\".format(root_dir, now)\n",
    "        self.mse_summary = tf.summary.scalar(\"MSE\", mse)\n",
    "        \n",
    "        \n",
    "    def __enter__(self):\n",
    "        self.file_writer = tf.summary.FileWriter(self.log_dir, tf.get_default_graph())\n",
    "        display(\"__enter__\")\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, type_, value, traceback):\n",
    "        self.file_writer.close()\n",
    "        display (\"__exit__\")\n",
    "        \n",
    "    def log_summary(self,step, feed_dict):\n",
    "        mse_str = self.mse_summary.eval(feed_dict=feed_dict)\n",
    "        self.file_writer.add_summary(mse_str, step)\n",
    "        return mse_str\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'__enter__'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'__exit__'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2.0686114 ],\n",
       "       [ 0.7755447 ],\n",
       "       [ 0.15780748],\n",
       "       [-0.07150789],\n",
       "       [ 0.10519094],\n",
       "       [ 0.01044764],\n",
       "       [-0.04112587],\n",
       "       [-0.66566163],\n",
       "       [-0.62580633]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perform_minibatch_gd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
